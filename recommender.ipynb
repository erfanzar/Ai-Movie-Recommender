{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "import json\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import time\n",
    "import ast\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   adult                              belongs_to_collection    budget  \\\n0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n1  False                                                NaN  65000000   \n2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n3  False                                                NaN  16000000   \n4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n\n                                              genres  \\\n0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n4                     [{'id': 35, 'name': 'Comedy'}]   \n\n                               homepage     id    imdb_id original_language  \\\n0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n1                                   NaN   8844  tt0113497                en   \n2                                   NaN  15602  tt0113228                en   \n3                                   NaN  31357  tt0114885                en   \n4                                   NaN  11862  tt0113041                en   \n\n                original_title  \\\n0                    Toy Story   \n1                      Jumanji   \n2             Grumpier Old Men   \n3            Waiting to Exhale   \n4  Father of the Bride Part II   \n\n                                            overview  ... release_date  \\\n0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n\n       revenue runtime                                   spoken_languages  \\\n0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n\n     status                                            tagline  \\\n0  Released                                                NaN   \n1  Released          Roll the dice and unleash the excitement!   \n2  Released  Still Yelling. Still Fighting. Still Ready for...   \n3  Released  Friends are the people who let you be yourself...   \n4  Released  Just When His World Is Back To Normal... He's ...   \n\n                         title  video vote_average vote_count  \n0                    Toy Story  False          7.7     5415.0  \n1                      Jumanji  False          6.9     2413.0  \n2             Grumpier Old Men  False          6.5       92.0  \n3            Waiting to Exhale  False          6.1       34.0  \n4  Father of the Bride Part II  False          5.7      173.0  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adult</th>\n      <th>belongs_to_collection</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>id</th>\n      <th>imdb_id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>...</th>\n      <th>release_date</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>video</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n      <td>30000000</td>\n      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n      <td>http://toystory.disney.com/toy-story</td>\n      <td>862</td>\n      <td>tt0114709</td>\n      <td>en</td>\n      <td>Toy Story</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>...</td>\n      <td>1995-10-30</td>\n      <td>373554033.0</td>\n      <td>81.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>NaN</td>\n      <td>Toy Story</td>\n      <td>False</td>\n      <td>7.7</td>\n      <td>5415.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>NaN</td>\n      <td>65000000</td>\n      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n      <td>NaN</td>\n      <td>8844</td>\n      <td>tt0113497</td>\n      <td>en</td>\n      <td>Jumanji</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>...</td>\n      <td>1995-12-15</td>\n      <td>262797249.0</td>\n      <td>104.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n      <td>Released</td>\n      <td>Roll the dice and unleash the excitement!</td>\n      <td>Jumanji</td>\n      <td>False</td>\n      <td>6.9</td>\n      <td>2413.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n      <td>0</td>\n      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n      <td>NaN</td>\n      <td>15602</td>\n      <td>tt0113228</td>\n      <td>en</td>\n      <td>Grumpier Old Men</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>...</td>\n      <td>1995-12-22</td>\n      <td>0.0</td>\n      <td>101.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n      <td>Grumpier Old Men</td>\n      <td>False</td>\n      <td>6.5</td>\n      <td>92.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>NaN</td>\n      <td>16000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n      <td>NaN</td>\n      <td>31357</td>\n      <td>tt0114885</td>\n      <td>en</td>\n      <td>Waiting to Exhale</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>...</td>\n      <td>1995-12-22</td>\n      <td>81452156.0</td>\n      <td>127.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Friends are the people who let you be yourself...</td>\n      <td>Waiting to Exhale</td>\n      <td>False</td>\n      <td>6.1</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n      <td>0</td>\n      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n      <td>NaN</td>\n      <td>11862</td>\n      <td>tt0113041</td>\n      <td>en</td>\n      <td>Father of the Bride Part II</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>...</td>\n      <td>1995-02-10</td>\n      <td>76578911.0</td>\n      <td>106.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Just When His World Is Back To Normal... He's ...</td>\n      <td>Father of the Bride Part II</td>\n      <td>False</td>\n      <td>5.7</td>\n      <td>173.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 24 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
    "data_csv.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_csv = data_csv.drop('imdb_id', axis=1)\n",
    "data_csv = data_csv.drop('id', axis=1)\n",
    "data_csv = data_csv.drop('poster_path', axis=1)\n",
    "data_csv = data_csv.drop('homepage', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['adult', 'belongs_to_collection', 'budget', 'genres',\n       'original_language', 'original_title', 'overview', 'popularity',\n       'production_companies', 'production_countries', 'release_date',\n       'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title',\n       'video', 'vote_average', 'vote_count'],\n      dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class DataSetManual(Dataset):\n",
    "    def __init__(self, data, vocab: dict = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if vocab is not None:\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            self.vocab = {}\n",
    "\n",
    "        self.categories = {}\n",
    "        self.adult = data['adult']\n",
    "        self.belongs_to_collection = data['belongs_to_collection']\n",
    "        self.budget = data['budget']\n",
    "        self.genres = data['genres']\n",
    "        self.original_language = data['original_language']\n",
    "        self.original_title = data['original_title']\n",
    "        self.overview = data['overview']\n",
    "        self.popularity = data['popularity']\n",
    "        self.production_companies = data['production_companies']\n",
    "        self.production_countries = data['production_countries']\n",
    "        self.release_date = data['release_date']\n",
    "        self.revenue = data['revenue']\n",
    "        self.runtime = data['runtime']\n",
    "        self.spoken_languages = data['spoken_languages']\n",
    "        self.status = data['status']\n",
    "        self.tagline = data['tagline']\n",
    "        self.tittle = data['title']\n",
    "        self.video = data['video']\n",
    "        self.vote_average = data['vote_average']\n",
    "        self.vote_count = data['vote_count']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adult) - 1\n",
    "\n",
    "    def __save_vocab__(self, name):\n",
    "        for i in range(self.__len__()):\n",
    "            print(f'% {round((i / self.__len__()) * 100, 3)}', end='\\r')\n",
    "            _, _ = self.__getitem__(i)\n",
    "        with open(f'{name}.yaml', 'a') as writer:\n",
    "            yaml.dump(dsm.vocab, writer)\n",
    "\n",
    "    def translate(self, *arg: [dict, int, list]) -> str:\n",
    "        ...\n",
    "        simulation_list = list(self.vocab)\n",
    "        s_pr = []\n",
    "        arg = list(arg)\n",
    "\n",
    "        for i in range(len(arg)):\n",
    "\n",
    "            if isinstance(arg[i], int):\n",
    "                s_pr.append(simulation_list[arg[i]])\n",
    "            if isinstance(arg[i], list) or isinstance(arg[i], np.ndarray) or isinstance(arg[i], tuple):\n",
    "\n",
    "                for v in range(len(arg[i])):\n",
    "                    s_pr.append(simulation_list[int(arg[i][v])])\n",
    "        s_pr = str(s_pr)\n",
    "        s_pr = s_pr.replace(']', '')\n",
    "        s_pr = s_pr.replace('[', '')\n",
    "        s_pr = s_pr.replace(',', '')\n",
    "        s_pr = s_pr.replace(\"'\", '')\n",
    "        s_pr = s_pr.replace('\"', '')\n",
    "        return s_pr\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        #adult\n",
    "        item = int(item)\n",
    "        if 'nan' not in self.vocab:\n",
    "            self.vocab['nan'] = len(self.vocab)\n",
    "        adult_out = []\n",
    "        adult = self.adult[item].lower()\n",
    "        if adult not in self.vocab:\n",
    "            self.vocab[adult] = len(self.vocab)\n",
    "        adult_out.append(self.vocab[adult])\n",
    "\n",
    "        popularity_out = 0.\n",
    "        if isinstance(self.popularity[item], float) or isinstance(self.popularity[item], int):\n",
    "            popularity_out = float(self.popularity[item])\n",
    "        # belongs_to_collection\n",
    "        belongs_to_collection_out = []\n",
    "        if not isinstance(self.belongs_to_collection[item], float):\n",
    "\n",
    "            sim = str(self.belongs_to_collection[item])\n",
    "            sim = ast.literal_eval(sim)\n",
    "            if not isinstance(sim, float):\n",
    "                belongs_to_collection = sim['name'].lower().split()\n",
    "            else:\n",
    "                belongs_to_collection = 'nan'\n",
    "        else:\n",
    "            belongs_to_collection = ['nan']\n",
    "        for word in belongs_to_collection:\n",
    "            if word not in self.vocab:\n",
    "                self.vocab[word] = len(self.vocab)\n",
    "            belongs_to_collection_out.append(self.vocab[word])\n",
    "\n",
    "        genres_out = []\n",
    "        genres_names = []\n",
    "        genres_str = str(self.genres[item])\n",
    "        genres_json = ast.literal_eval(genres_str)\n",
    "        if self.genres[item] != 'nan':\n",
    "            for i in range(len(genres_json)):\n",
    "                genres_names.append(genres_json[i]['name'].lower())\n",
    "\n",
    "            for word in genres_names:\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                if word not in self.categories:\n",
    "                    self.categories[word] = len(self.categories)\n",
    "                genres_out.append(self.categories[word])\n",
    "        else:\n",
    "            genres_out = self.vocab['nan']\n",
    "        o_language_out = []\n",
    "        if self.original_language[item] != '[]' and not isinstance(self.original_language[item], float):\n",
    "            o_language = self.original_language[item]\n",
    "            o_language = o_language.lower().split()\n",
    "            if self.original_language[item] != 'nan':\n",
    "                for word in o_language:\n",
    "                    if word not in self.vocab:\n",
    "                        self.vocab[word] = len(self.vocab)\n",
    "                    o_language_out.append(self.vocab[word])\n",
    "        else:\n",
    "            o_language_out = self.vocab['nan']\n",
    "\n",
    "        budget_out = 0\n",
    "        if isinstance(self.budget[item], int) or isinstance(self.budget[item], float):\n",
    "            budget_out = int(self.budget[item])\n",
    "        else:\n",
    "            budget_out = 0\n",
    "        original_title_out = []\n",
    "        original_title = self.original_title[item]\n",
    "        original_title = original_title.lower().split()\n",
    "        if self.original_title[item] != 'nan':\n",
    "            for word in original_title:\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                original_title_out.append(self.vocab[word])\n",
    "\n",
    "        overview_out = []\n",
    "        overview = self.overview[item]\n",
    "        if self.overview[item] != 'nan' and not isinstance(overview, float):\n",
    "\n",
    "            overview = overview.lower().split()\n",
    "            for word in overview:\n",
    "                gs = word.find('.')\n",
    "                if gs is not None:\n",
    "                    word = word.replace('.', '')\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                overview_out.append(self.vocab[word])\n",
    "        else:\n",
    "            overview_out = self.vocab['nan']\n",
    "        production_companies_out = []\n",
    "        if not isinstance(self.production_companies[item], float):\n",
    "            if self.production_companies[item] != '[]' and len(self.production_companies[item]) != 0:\n",
    "\n",
    "                production_companies = str(self.production_companies[item])\n",
    "                production_companies = ast.literal_eval(production_companies)\n",
    "                if not isinstance(production_companies, bool):\n",
    "                    if len(production_companies) > 1:\n",
    "                        for i in range(len(production_companies)):\n",
    "                            spa = production_companies[i]['name'].lower().split()\n",
    "                            for word in spa:\n",
    "                                gs = word.find('.')\n",
    "                                if gs is not None:\n",
    "                                    word = word.replace('.', '')\n",
    "                                if word not in self.vocab:\n",
    "                                    self.vocab[word] = len(self.vocab)\n",
    "                                production_companies_out.append(self.vocab[word])\n",
    "                    else:\n",
    "                        spa = production_companies[0]['name'].lower().split()\n",
    "                        for word in spa:\n",
    "                            gs = word.find('.')\n",
    "                            if gs is not None:\n",
    "                                word = word.replace('.', '')\n",
    "                            if word not in self.vocab:\n",
    "                                self.vocab[word] = len(self.vocab)\n",
    "                            production_companies_out.append(self.vocab[word])\n",
    "                else:\n",
    "                    production_companies_out = self.vocab['nan']\n",
    "            else:\n",
    "                production_companies_out = self.vocab['nan']\n",
    "        else:\n",
    "            production_companies_out = self.vocab['nan']\n",
    "        production_countries_out = []\n",
    "        if self.production_countries[item] != 'nan' and not isinstance(self.production_countries[item], float):\n",
    "            production_countries = str(self.production_countries[item])\n",
    "\n",
    "            production_countries = ast.literal_eval(production_countries)\n",
    "            if not isinstance(production_countries, float):\n",
    "                if len(production_countries) != 0:\n",
    "                    for i in range(len(production_countries)):\n",
    "                        spa = production_countries[i]['name'].lower().split()\n",
    "\n",
    "                        for word in spa:\n",
    "                            gs = word.find('.')\n",
    "                            if gs is not None:\n",
    "                                word = word.replace('.', '')\n",
    "                            if word not in self.vocab:\n",
    "                                self.vocab[word] = len(self.vocab)\n",
    "                            production_countries_out.append(self.vocab[word])\n",
    "            else:\n",
    "                production_countries_out = self.vocab['nan']\n",
    "        else:\n",
    "            production_countries_out = self.vocab['nan']\n",
    "        release_date_out = []\n",
    "        if self.release_date[item] != 'nan' and not isinstance(self.release_date[item], float):\n",
    "            release_date = self.release_date[item]\n",
    "            release_date = release_date.lower().split()\n",
    "            for word in release_date:\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                release_date_out.append(self.vocab[word])\n",
    "        else:\n",
    "            release_date_out = self.vocab['nan']\n",
    "\n",
    "        revenue_out = []\n",
    "        revenue = self.revenue[item]\n",
    "        revenue_out.append(revenue)\n",
    "\n",
    "        spoken_languages_out = []\n",
    "        if self.spoken_languages[item] != 'nan' and not isinstance(self.spoken_languages[item], float):\n",
    "            spoken_languages = str(self.spoken_languages[item])\n",
    "            spoken_languages = ast.literal_eval(spoken_languages)\n",
    "            for i in range(len(spoken_languages)):\n",
    "                spa = spoken_languages[i]['name'].lower().split()\n",
    "                for word in spa:\n",
    "                    gs = word.find('.')\n",
    "                    if gs is not None:\n",
    "                        word = word.replace('.', '')\n",
    "                    if word not in self.vocab:\n",
    "                        self.vocab[word] = len(self.vocab)\n",
    "                    spoken_languages_out.append(self.vocab[word])\n",
    "        else:\n",
    "            spoken_languages_out = self.vocab['nan']\n",
    "        status_out = []\n",
    "        if self.status[item] != 'nan' and not isinstance(self.status[item], float):\n",
    "            status = self.status[item]\n",
    "            status = status.lower().split()\n",
    "            for word in status:\n",
    "                gs = word.find('.')\n",
    "                if gs is not None:\n",
    "                    word = word.replace('.', '')\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                status_out.append(self.vocab[word])\n",
    "        else:\n",
    "            status_out = self.vocab['nan']\n",
    "        tagline_out = []\n",
    "\n",
    "        if self.tagline[item] != 'nan':\n",
    "            tagline = 0\n",
    "        else:\n",
    "            tagline = self.tagline[item]\n",
    "\n",
    "        # tagline = self.tagline[item] if self.tagline[item] != 'nan' else 0\n",
    "\n",
    "        tagline = str(tagline)\n",
    "        tagline_out.append(tagline)\n",
    "\n",
    "        title_out = []\n",
    "        tittle = self.tittle[item]\n",
    "        if self.tittle[item] != 'nan' and not isinstance(self.tittle[item], float):\n",
    "            tittle = tittle.lower().split()\n",
    "            for word in tittle:\n",
    "                gs = word.find('.')\n",
    "                if gs is not None:\n",
    "                    word = word.replace('.', '')\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                title_out.append(self.vocab[word])\n",
    "        else:\n",
    "            title_out = self.vocab['nan']\n",
    "        video_out = []\n",
    "        video = str(self.video[item])\n",
    "        video = video.lower().split()\n",
    "        for word in video:\n",
    "            gs = word.find('.')\n",
    "            if gs is not None:\n",
    "                word = word.replace('.', '')\n",
    "            if word not in self.vocab:\n",
    "                self.vocab[word] = len(self.vocab)\n",
    "            video_out.append(self.vocab[word])\n",
    "\n",
    "        vote_average_out = []\n",
    "        vote_average = self.vote_average[item]\n",
    "        vote_average_out.append(vote_average)\n",
    "\n",
    "        vote_count_out = []\n",
    "        vote_count = self.vote_count[item]\n",
    "        vote_count_out.append(vote_count)\n",
    "        if isinstance(status_out, list):\n",
    "            status_out = status_out[0]\n",
    "        elif isinstance(status_out, int):\n",
    "            status_out = status_out\n",
    "\n",
    "        outputs = {\n",
    "            'adult': np.array(adult_out, dtype=np.float64),\n",
    "            'belongs_to_collection': np.array(belongs_to_collection_out, dtype=np.float64),\n",
    "            'budget': np.array(budget_out, dtype=np.float64),\n",
    "            'original_language': np.array(o_language_out, dtype=np.float64),\n",
    "            'original_title': np.array(original_title_out, dtype=np.float64),\n",
    "            'overview': np.array(overview_out, dtype=np.float64),\n",
    "            'popularity': np.array(popularity_out, dtype=np.float64),\n",
    "            'production_companies': np.array(production_companies_out, dtype=np.float64),\n",
    "            'production_countries': np.array(production_countries_out, dtype=np.float64),\n",
    "            'release_date': np.array(release_date_out, dtype=np.float64),\n",
    "            'revenue': np.array(revenue_out, dtype=np.float64),\n",
    "            'runtime': np.array(self.runtime[item], dtype=np.float64),\n",
    "            'spoken_languages': np.array(spoken_languages_out, dtype=np.float64),\n",
    "            'status': np.array(status_out, dtype=np.float64),\n",
    "            'tagline': np.array(int(float(tagline_out[0])), dtype=np.float64),\n",
    "            'title': np.array(title_out, dtype=np.float64),\n",
    "            'video': np.array(video_out, dtype=np.float64),\n",
    "            'vote_average': np.array(vote_average_out, dtype=np.float64),\n",
    "            'vote_count': np.array(vote_count_out, dtype=np.float64),\n",
    "        }\n",
    "\n",
    "        cfk = np.zeros(32, dtype=np.float64)\n",
    "\n",
    "        for i in range(len(genres_out)):\n",
    "            cfk[genres_out[i]] = 1\n",
    "\n",
    "        targets = {\n",
    "            'genres': cfk,\n",
    "        }\n",
    "\n",
    "        return outputs, targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "dsm = DataSetManual(data_csv)\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE = 'cpu'\n",
    "# DEVICE = 'cuda:0'\n",
    "# dsm.__save_vocab__('vocab')\n",
    "# print(dsm.categories)\n",
    "# print(len(dsm.categories))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "dataLd = DataLoader(\n",
    "    dsm,\n",
    "    batch_size=4,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_embedding_1: int = 500000,\n",
    "                 embedding_dim_1: int = 400,\n",
    "                 num_embedding_2: int = 400000,\n",
    "                 embedding_dim_2: int = 400,\n",
    "                 num_embedding_3: int = 500000,\n",
    "                 embedding_dim_3: int = 400,\n",
    "                 num_embedding_4: int = 500000,\n",
    "                 embedding_dim_4: int = 400,\n",
    "                 num_embedding_5: int = 500000,\n",
    "                 embedding_dim_5: int = 400,\n",
    "                 num_embedding_6: int = 400000,\n",
    "                 embedding_dim_6: int = 400,\n",
    "                 num_embedding_7: int = 500000,\n",
    "                 embedding_dim_7: int = 400,\n",
    "                 num_embedding_8: int = 500000,\n",
    "                 embedding_dim_8: int = 400,\n",
    "                 num_embedding_9: int = 500000,\n",
    "                 embedding_dim_9: int = 400,\n",
    "                 num_embedding_10: int = 400000,\n",
    "                 embedding_dim_10: int = 400,\n",
    "\n",
    "                 lstm_layers_1: int = 1,\n",
    "                 lstm_hidden_num_1: int = 15,\n",
    "                 lstm_layers_2: int = 1,\n",
    "                 lstm_hidden_num_2: int = 15,\n",
    "                 lstm_layers_3: int = 1,\n",
    "                 lstm_hidden_num_3: int = 15,\n",
    "                 lstm_layers_4: int = 1,\n",
    "                 lstm_hidden_num_4: int = 15,\n",
    "                 lstm_layers_5: int = 1,\n",
    "                 lstm_hidden_num_5: int = 15,\n",
    "                 lstm_layers_6: int = 1,\n",
    "                 lstm_hidden_num_6: int = 15,\n",
    "                 lstm_layers_7: int = 1,\n",
    "                 lstm_hidden_num_7: int = 15,\n",
    "                 lstm_layers_8: int = 1,\n",
    "                 lstm_hidden_num_8: int = 15,\n",
    "                 lstm_layers_9: int = 1,\n",
    "                 lstm_hidden_num_9: int = 15,\n",
    "                 lstm_layers_10: int = 1,\n",
    "                 lstm_hidden_num_10: int = 15,\n",
    "\n",
    "                 output_size: int = 15):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.num_embedding_1 = num_embedding_1\n",
    "        self.embedding_dim_1 = embedding_dim_1\n",
    "        self.num_embedding_2 = num_embedding_2\n",
    "        self.embedding_dim_2 = embedding_dim_2\n",
    "        self.num_embedding_3 = num_embedding_3\n",
    "        self.embedding_dim_3 = embedding_dim_3\n",
    "        self.num_embedding_4 = num_embedding_4\n",
    "        self.embedding_dim_4 = embedding_dim_4\n",
    "        self.num_embedding_5 = num_embedding_5\n",
    "        self.embedding_dim_5 = embedding_dim_5\n",
    "        self.num_embedding_6 = num_embedding_6\n",
    "        self.embedding_dim_6 = embedding_dim_6\n",
    "        self.num_embedding_7 = num_embedding_7\n",
    "        self.embedding_dim_7 = embedding_dim_7\n",
    "        self.num_embedding_8 = num_embedding_8\n",
    "        self.embedding_dim_8 = embedding_dim_8\n",
    "        self.num_embedding_9 = num_embedding_9\n",
    "        self.embedding_dim_9 = embedding_dim_9\n",
    "        self.num_embedding_10 = num_embedding_10\n",
    "        self.embedding_dim_10 = embedding_dim_10\n",
    "\n",
    "        self.lstm_hidden_num_1 = lstm_hidden_num_1\n",
    "        self.lstm_hidden_num_2 = lstm_hidden_num_2\n",
    "        self.lstm_hidden_num_3 = lstm_hidden_num_3\n",
    "        self.lstm_hidden_num_4 = lstm_hidden_num_4\n",
    "        self.lstm_hidden_num_5 = lstm_hidden_num_5\n",
    "        self.lstm_hidden_num_6 = lstm_hidden_num_6\n",
    "        self.lstm_hidden_num_7 = lstm_hidden_num_7\n",
    "        self.lstm_hidden_num_8 = lstm_hidden_num_8\n",
    "        self.lstm_hidden_num_9 = lstm_hidden_num_9\n",
    "        self.lstm_hidden_num_10 = lstm_hidden_num_10\n",
    "\n",
    "        self.lstm_layers_1 = lstm_layers_1\n",
    "        self.lstm_layers_2 = lstm_layers_2\n",
    "        self.lstm_layers_3 = lstm_layers_3\n",
    "        self.lstm_layers_4 = lstm_layers_4\n",
    "        self.lstm_layers_5 = lstm_layers_5\n",
    "        self.lstm_layers_6 = lstm_layers_6\n",
    "        self.lstm_layers_7 = lstm_layers_7\n",
    "        self.lstm_layers_8 = lstm_layers_8\n",
    "        self.lstm_layers_9 = lstm_layers_9\n",
    "        self.lstm_layers_10 = lstm_layers_10\n",
    "\n",
    "        self.fc_adult_0 = nn.Linear(1, 2)\n",
    "        self.fc_adult_1 = nn.Linear(2, 1)\n",
    "\n",
    "        self.fc_budget_0 = nn.Linear(1, 10)\n",
    "        self.fc_budget_1 = nn.Linear(10, 1)\n",
    "\n",
    "        self.fc_popularity_0 = nn.Linear(1, 10)\n",
    "        self.fc_popularity_1 = nn.Linear(10, 1)\n",
    "\n",
    "        self.fc_revenue_0 = nn.Linear(1, 30)\n",
    "        self.fc_revenue_1 = nn.Linear(30, 1)\n",
    "\n",
    "        self.fc_runtime_0 = nn.Linear(1, 10)\n",
    "        self.fc_runtime_1 = nn.Linear(10, 1)\n",
    "\n",
    "        self.fc_status_0 = nn.Linear(1, 2)\n",
    "        self.fc_status_1 = nn.Linear(2, 1)\n",
    "\n",
    "        self.fc_video_0 = nn.Linear(1, 2)\n",
    "        self.fc_video_1 = nn.Linear(2, 1)\n",
    "\n",
    "        self.fc_vote_average_0 = nn.Linear(1, 10)\n",
    "        self.fc_vote_average_1 = nn.Linear(10, 1)\n",
    "\n",
    "        self.fc_vote_count_0 = nn.Linear(1, 10)\n",
    "        self.fc_vote_count_1 = nn.Linear(10, 1)\n",
    "\n",
    "        self.embedding_layer_1 = nn.Embedding(num_embeddings=num_embedding_1, embedding_dim=embedding_dim_1)\n",
    "        self.embedding_layer_2 = nn.Embedding(num_embeddings=num_embedding_2, embedding_dim=embedding_dim_2)\n",
    "        self.embedding_layer_3 = nn.Embedding(num_embeddings=num_embedding_3, embedding_dim=embedding_dim_3)\n",
    "        self.embedding_layer_4 = nn.Embedding(num_embeddings=num_embedding_4, embedding_dim=embedding_dim_4)\n",
    "        self.embedding_layer_5 = nn.Embedding(num_embeddings=num_embedding_5, embedding_dim=embedding_dim_5)\n",
    "        self.embedding_layer_6 = nn.Embedding(num_embeddings=num_embedding_6, embedding_dim=embedding_dim_6)\n",
    "        self.embedding_layer_7 = nn.Embedding(num_embeddings=num_embedding_7, embedding_dim=embedding_dim_7)\n",
    "        self.embedding_layer_8 = nn.Embedding(num_embeddings=num_embedding_8, embedding_dim=embedding_dim_8)\n",
    "        self.embedding_layer_9 = nn.Embedding(num_embeddings=num_embedding_9, embedding_dim=embedding_dim_9)\n",
    "        self.embedding_layer_10 = nn.Embedding(num_embeddings=num_embedding_10, embedding_dim=embedding_dim_10)\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(num_layers=lstm_layers_1, hidden_size=lstm_hidden_num_1, input_size=embedding_dim_1)\n",
    "        self.lstm_2 = nn.LSTM(num_layers=lstm_layers_2, hidden_size=lstm_hidden_num_2, input_size=embedding_dim_2)\n",
    "        self.lstm_3 = nn.LSTM(num_layers=lstm_layers_3, hidden_size=lstm_hidden_num_3, input_size=embedding_dim_3)\n",
    "        self.lstm_4 = nn.LSTM(num_layers=lstm_layers_4, hidden_size=lstm_hidden_num_4, input_size=embedding_dim_4)\n",
    "        self.lstm_5 = nn.LSTM(num_layers=lstm_layers_5, hidden_size=lstm_hidden_num_5, input_size=embedding_dim_5)\n",
    "        self.lstm_6 = nn.LSTM(num_layers=lstm_layers_6, hidden_size=lstm_hidden_num_6, input_size=embedding_dim_6)\n",
    "        self.lstm_7 = nn.LSTM(num_layers=lstm_layers_7, hidden_size=lstm_hidden_num_7, input_size=embedding_dim_7)\n",
    "        self.lstm_8 = nn.LSTM(num_layers=lstm_layers_8, hidden_size=lstm_hidden_num_8, input_size=embedding_dim_8)\n",
    "        self.lstm_9 = nn.LSTM(num_layers=lstm_layers_9, hidden_size=lstm_hidden_num_9, input_size=embedding_dim_9)\n",
    "        self.lstm_10 = nn.LSTM(num_layers=lstm_layers_10, hidden_size=lstm_hidden_num_10, input_size=embedding_dim_10)\n",
    "\n",
    "        self.fc0_1 = nn.Linear(lstm_hidden_num_1, lstm_hidden_num_1 * 2)\n",
    "        self.relu_0_1 = nn.ReLU()\n",
    "        self.fc1_1 = nn.Linear(lstm_hidden_num_1 * 2, 8)\n",
    "        self.relu_1_1 = nn.ReLU()\n",
    "\n",
    "        self.fc0_2 = nn.Linear(lstm_hidden_num_2, lstm_hidden_num_2 * 2)\n",
    "        self.relu_0_2 = nn.ReLU()\n",
    "        self.fc1_2 = nn.Linear(lstm_hidden_num_2 * 2, 8)\n",
    "        self.relu_1_2 = nn.ReLU()\n",
    "\n",
    "        self.fc0_3 = nn.Linear(lstm_hidden_num_3, lstm_hidden_num_3 * 2)\n",
    "        self.relu_0_3 = nn.ReLU()\n",
    "        self.fc1_3 = nn.Linear(lstm_hidden_num_4 * 2, 8)\n",
    "        self.relu_1_3 = nn.ReLU()\n",
    "\n",
    "        self.fc0_4 = nn.Linear(lstm_hidden_num_4, lstm_hidden_num_4 * 2)\n",
    "        self.relu_0_4 = nn.ReLU()\n",
    "        self.fc1_4 = nn.Linear(lstm_hidden_num_4 * 2, 8)\n",
    "        self.relu_1_4 = nn.ReLU()\n",
    "\n",
    "        self.fc0_5 = nn.Linear(lstm_hidden_num_5, lstm_hidden_num_5 * 2)\n",
    "        self.relu_0_5 = nn.ReLU()\n",
    "        self.fc1_5 = nn.Linear(lstm_hidden_num_5 * 2, 8)\n",
    "        self.relu_1_5 = nn.ReLU()\n",
    "\n",
    "        self.fc0_6 = nn.Linear(lstm_hidden_num_6, lstm_hidden_num_6 * 2)\n",
    "        self.relu_0_6 = nn.ReLU()\n",
    "        self.fc1_6 = nn.Linear(lstm_hidden_num_6 * 2, 8)\n",
    "        self.relu_1_6 = nn.ReLU()\n",
    "\n",
    "        self.fc0_7 = nn.Linear(lstm_hidden_num_7, lstm_hidden_num_7 * 2)\n",
    "        self.relu_0_7 = nn.ReLU()\n",
    "        self.fc1_7 = nn.Linear(lstm_hidden_num_7 * 2, 8)\n",
    "        self.relu_1_7 = nn.ReLU()\n",
    "\n",
    "        self.fc0_8 = nn.Linear(lstm_hidden_num_8, lstm_hidden_num_8 * 2)\n",
    "        self.relu_0_8 = nn.ReLU()\n",
    "        self.fc1_8 = nn.Linear(lstm_hidden_num_8 * 2, 8)\n",
    "        self.relu_1_8 = nn.ReLU()\n",
    "\n",
    "        self.fc0_9 = nn.Linear(lstm_hidden_num_9, lstm_hidden_num_9 * 2)\n",
    "        self.relu_0_9 = nn.ReLU()\n",
    "        self.fc1_9 = nn.Linear(lstm_hidden_num_9 * 2, 8)\n",
    "        self.relu_1_9 = nn.ReLU()\n",
    "\n",
    "        self.fc0_10 = nn.Linear(lstm_hidden_num_10, lstm_hidden_num_10 * 2)\n",
    "        self.relu_0_10 = nn.ReLU()\n",
    "        self.fc1_10 = nn.Linear(lstm_hidden_num_10 * 2, 8)\n",
    "        self.relu_1_10 = nn.ReLU()\n",
    "\n",
    "        self.output_layer = nn.Linear(8, 32)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "        print('\\033[38;2;255;0;0initialization Done\\033[38;2;255;255;255m')\n",
    "\n",
    "    def forward(self,\n",
    "                adult: torch.Tensor,\n",
    "                belongs_to_collection: torch.Tensor,\n",
    "                budget: torch.Tensor,\n",
    "                original_language: torch.Tensor,\n",
    "                original_title: torch.Tensor,\n",
    "                overview: torch.Tensor,\n",
    "                popularity: torch.Tensor,\n",
    "                production_companies: torch.Tensor,\n",
    "                production_countries: torch.Tensor,\n",
    "                release_date: torch.Tensor,\n",
    "                revenue: torch.Tensor,\n",
    "                runtime: torch.Tensor,\n",
    "                spoken_languages: torch.Tensor,\n",
    "                status: torch.Tensor,\n",
    "                tagline: torch.Tensor,\n",
    "                title: torch.Tensor,\n",
    "                video: torch.Tensor,\n",
    "                vote_average: torch.Tensor,\n",
    "\n",
    "                ) -> torch.Tensor:\n",
    "        ...\n",
    "\n",
    "        adult_out = f.relu(self.fc_adult_1(f.relu(self.fc_adult_0(adult))))\n",
    "        budget_out = f.relu(self.fc_budget_1(f.relu(self.fc_budget_0(budget))))\n",
    "        popularity_out = f.relu(self.fc_popularity_1(f.relu(self.fc_popularity_0(popularity))))\n",
    "        revenue_out = f.relu(self.fc_revenue_1(f.relu(self.fc_revenue_0(revenue))))\n",
    "        runtime_out = f.relu(self.fc_runtime_1(f.relu(self.fc_runtime_0(runtime))))\n",
    "        if len(status.shape) >= 1:\n",
    "            status_out = f.relu(self.fc_status_1(f.relu(self.fc_status_0(status))))\n",
    "        else:\n",
    "            status = status.view(1, -1)\n",
    "            status_out = f.relu(self.fc_status_1(f.relu(self.fc_status_0(status))))\n",
    "        video_out = f.relu(self.fc_video_1(f.relu(self.fc_video_0(video))))\n",
    "        vote_average_out = f.relu(self.fc_vote_average_1(f.relu(self.fc_vote_average_0(vote_average))))\n",
    "\n",
    "        non_text = torch.tensor(\n",
    "            [adult_out[0], budget_out[0], popularity_out[0], revenue_out[0], runtime_out[0], status_out[0],\n",
    "             video_out[0], vote_average_out[0]])\n",
    "        non_text = non_text.view(2, -1)\n",
    "\n",
    "        belongs_to_collection_x_0 = self.embedding_layer_1(belongs_to_collection)  #Done\n",
    "\n",
    "        original_language_x_0 = self.embedding_layer_2(original_language)  #Done\n",
    "\n",
    "        original_title_x_0 = self.embedding_layer_3(original_title)  #Done\n",
    "\n",
    "        overview_x_0 = self.embedding_layer_4(overview)  #Done\n",
    "\n",
    "        production_companies_x_0 = self.embedding_layer_5(production_companies)  #Done\n",
    "\n",
    "        production_countries_x_0 = self.embedding_layer_6(production_countries)  #Done\n",
    "\n",
    "        release_date_x_0 = self.embedding_layer_7(release_date)  #Done\n",
    "\n",
    "        spoken_languages_x_0 = self.embedding_layer_8(spoken_languages)  #Done\n",
    "\n",
    "        tagline_x_0 = self.embedding_layer_9(tagline)  # Done\n",
    "\n",
    "        title_x_0 = self.embedding_layer_10(title)  # Done\n",
    "\n",
    "        h0_1 = torch.zeros(self.lstm_layers_1, belongs_to_collection_x_0.size()[0], self.lstm_hidden_num_1).to(\n",
    "            DEVICE) if len(\n",
    "            belongs_to_collection_x_0.shape) > 1 else torch.zeros(self.lstm_layers_1, 1, self.lstm_hidden_num_1).to(\n",
    "            DEVICE)\n",
    "        c0_1 = torch.zeros(self.lstm_layers_1, belongs_to_collection_x_0.size()[0], self.lstm_hidden_num_1).to(\n",
    "            DEVICE) if len(\n",
    "            belongs_to_collection_x_0.shape) > 1 else torch.zeros(self.lstm_layers_1, 1, self.lstm_hidden_num_1).to(\n",
    "            DEVICE)\n",
    "\n",
    "        h0_2 = torch.zeros(self.lstm_layers_2, original_language_x_0.size()[0], self.lstm_hidden_num_2).to(\n",
    "            DEVICE) if len(\n",
    "            original_language_x_0.shape) > 1 else torch.zeros(self.lstm_layers_2, 1, self.lstm_hidden_num_2).to(DEVICE)\n",
    "        c0_2 = torch.zeros(self.lstm_layers_2, original_language_x_0.size()[0], self.lstm_hidden_num_2).to(\n",
    "            DEVICE) if len(\n",
    "            original_language_x_0.shape) > 1 else torch.zeros(self.lstm_layers_2, 1, self.lstm_hidden_num_2).to(DEVICE)\n",
    "\n",
    "        h0_3 = torch.zeros(self.lstm_layers_3, original_title_x_0.size()[0], self.lstm_hidden_num_3).to(DEVICE) if len(\n",
    "            original_title_x_0.shape) > 1 else torch.zeros(self.lstm_layers_3, 1, self.lstm_hidden_num_3).to(DEVICE)\n",
    "        c0_3 = torch.zeros(self.lstm_layers_3, original_title_x_0.size()[0], self.lstm_hidden_num_3).to(DEVICE) if len(\n",
    "            original_title_x_0.shape) > 1 else torch.zeros(self.lstm_layers_3, 1, self.lstm_hidden_num_3).to(DEVICE)\n",
    "\n",
    "        if len(overview_x_0.shape) > 1:\n",
    "            h0_4 = torch.zeros(self.lstm_layers_4, overview_x_0.size()[0], self.lstm_hidden_num_4).to(DEVICE)\n",
    "            c0_4 = torch.zeros(self.lstm_layers_4, overview_x_0.size()[0], self.lstm_hidden_num_4).to(DEVICE)\n",
    "        else:\n",
    "            h0_4 = torch.zeros(self.lstm_layers_4, 1, self.lstm_hidden_num_4).to(DEVICE)\n",
    "            c0_4 = torch.zeros(self.lstm_layers_4, 1, self.lstm_hidden_num_4).to(DEVICE)\n",
    "\n",
    "        if len(production_companies_x_0.shape) > 1:\n",
    "            h0_5 = torch.zeros(self.lstm_layers_5, production_companies_x_0.size()[0], self.lstm_hidden_num_5).to(\n",
    "                DEVICE)\n",
    "            c0_5 = torch.zeros(self.lstm_layers_5, production_companies_x_0.size()[0], self.lstm_hidden_num_5).to(\n",
    "                DEVICE)\n",
    "        else:\n",
    "            h0_5 = torch.zeros(self.lstm_layers_5, 1, self.lstm_hidden_num_5).to(DEVICE)\n",
    "            c0_5 = torch.zeros(self.lstm_layers_5, 1, self.lstm_hidden_num_5).to(DEVICE)\n",
    "\n",
    "        h0_6 = torch.zeros(self.lstm_layers_6, production_countries_x_0.size()[0], self.lstm_hidden_num_6).to(\n",
    "            DEVICE) if len(\n",
    "            production_countries_x_0.shape) > 1 else torch.zeros(self.lstm_layers_6, 1,\n",
    "                                                                            self.lstm_hidden_num_6).to(DEVICE)\n",
    "        c0_6 = torch.zeros(self.lstm_layers_6, production_countries_x_0.size()[0], self.lstm_hidden_num_6).to(\n",
    "            DEVICE) if len(\n",
    "            production_countries_x_0.shape) > 1 else torch.zeros(self.lstm_layers_6, 1,\n",
    "                                                                            self.lstm_hidden_num_6).to(DEVICE)\n",
    "\n",
    "        if len(release_date_x_0.shape) > 1:\n",
    "            h0_7 = torch.zeros(self.lstm_layers_7, release_date_x_0.size()[0], self.lstm_hidden_num_7).to(DEVICE)\n",
    "            c0_7 = torch.zeros(self.lstm_layers_7, release_date_x_0.size()[0], self.lstm_hidden_num_7).to(DEVICE)\n",
    "        else:\n",
    "            h0_7 = torch.zeros(self.lstm_layers_7, 1, self.lstm_hidden_num_7).to(DEVICE)\n",
    "            c0_7 = torch.zeros(self.lstm_layers_7, 1, self.lstm_hidden_num_7).to(DEVICE)\n",
    "\n",
    "        if len(spoken_languages_x_0.shape) > 1:\n",
    "            h0_8 = torch.zeros(self.lstm_layers_8, spoken_languages_x_0.size()[0], self.lstm_hidden_num_8).to(DEVICE)\n",
    "            c0_8 = torch.zeros(self.lstm_layers_8, spoken_languages_x_0.size()[0], self.lstm_hidden_num_8).to(DEVICE)\n",
    "        else:\n",
    "            h0_8 = torch.zeros(self.lstm_layers_8, 1, self.lstm_hidden_num_8).to(DEVICE)\n",
    "            c0_8 = torch.zeros(self.lstm_layers_8, 1, self.lstm_hidden_num_8).to(DEVICE)\n",
    "\n",
    "        h0_9 = torch.zeros(self.lstm_layers_9, 1, self.lstm_hidden_num_9).to(DEVICE) if len(\n",
    "            tagline_x_0.shape) == 1 else torch.zeros(self.lstm_layers_9, tagline_x_0.size()[0],\n",
    "                                                     self.lstm_hidden_num_9).to(DEVICE)\n",
    "        c0_9 = torch.zeros(self.lstm_layers_9, 1, self.lstm_hidden_num_9).to(DEVICE) if len(\n",
    "            tagline_x_0.shape) == 1 else torch.zeros(self.lstm_layers_9, tagline_x_0.size()[0],\n",
    "                                                     self.lstm_hidden_num_9).to(DEVICE)\n",
    "\n",
    "        h0_10 = torch.zeros(self.lstm_layers_10, title_x_0.size()[0], self.lstm_hidden_num_10).to(DEVICE) if len(\n",
    "            title_x_0.shape) > 1 else torch.zeros(self.lstm_layers_10, 1, self.lstm_hidden_num_10).to(DEVICE)\n",
    "        c0_10 = torch.zeros(self.lstm_layers_10, title_x_0.size()[0], self.lstm_hidden_num_10).to(DEVICE) if len(\n",
    "            title_x_0.shape) > 1 else torch.zeros(self.lstm_layers_10, 1, self.lstm_hidden_num_10).to(DEVICE)\n",
    "\n",
    "        # h0_1 = torch.zeros(self.lstm_layers_1, 1, self.lstm_hidden_num_1)\n",
    "        # c0_1 = torch.zeros(self.lstm_layers_1, 1, self.lstm_hidden_num_1)\n",
    "        #\n",
    "        # h0_2 = torch.zeros(self.lstm_layers_2, original_language_x_0.size()[0], self.lstm_hidden_num_2)\n",
    "        # c0_2 = torch.zeros(self.lstm_layers_2, original_language_x_0.size()[0], self.lstm_hidden_num_2)\n",
    "        #\n",
    "        # h0_3 = torch.zeros(self.lstm_layers_3, original_title_x_0.size()[0], self.lstm_hidden_num_3)\n",
    "        # c0_3 = torch.zeros(self.lstm_layers_3, original_title_x_0.size()[0], self.lstm_hidden_num_3)\n",
    "        #\n",
    "        # h0_4 = torch.zeros(self.lstm_layers_4, overview_x_0.size()[0], self.lstm_hidden_num_4)\n",
    "        # c0_4 = torch.zeros(self.lstm_layers_4, overview_x_0.size()[0], self.lstm_hidden_num_4)\n",
    "        #\n",
    "        # h0_5 = torch.zeros(self.lstm_layers_5, production_companies_x_0.size()[0], self.lstm_hidden_num_5)\n",
    "        # c0_5 = torch.zeros(self.lstm_layers_5, production_companies_x_0.size()[0], self.lstm_hidden_num_5)\n",
    "        #\n",
    "        # h0_6 = torch.zeros(self.lstm_layers_6, production_countries_x_0.size()[0], self.lstm_hidden_num_6)\n",
    "        # c0_6 = torch.zeros(self.lstm_layers_6, production_countries_x_0.size()[0], self.lstm_hidden_num_6)\n",
    "        #\n",
    "        # h0_7 = torch.zeros(self.lstm_layers_7, release_date_x_0.size()[0], self.lstm_hidden_num_7)\n",
    "        # c0_7 = torch.zeros(self.lstm_layers_7, release_date_x_0.size()[0], self.lstm_hidden_num_7)\n",
    "        #\n",
    "        # h0_8 = torch.zeros(self.lstm_layers_8, spoken_languages_x_0.size()[0], self.lstm_hidden_num_8)\n",
    "        # c0_8 = torch.zeros(self.lstm_layers_8, spoken_languages_x_0.size()[0], self.lstm_hidden_num_8)\n",
    "        #\n",
    "        # h0_9 = torch.zeros(self.lstm_layers_9, tagline_x_0.size()[0], self.lstm_hidden_num_9)\n",
    "        # c0_9 = torch.zeros(self.lstm_layers_9, tagline_x_0.size()[0], self.lstm_hidden_num_9)\n",
    "        #\n",
    "        # h0_10 = torch.zeros(self.lstm_layers_10, title_x_0.size()[0], self.lstm_hidden_num_10)\n",
    "        # c0_10 = torch.zeros(self.lstm_layers_10, title_x_0.size()[0], self.lstm_hidden_num_10)\n",
    "\n",
    "        # OverflowError\n",
    "        belongs_to_collection_x_0 = belongs_to_collection_x_0.view(1, belongs_to_collection_x_0.size()[0],\n",
    "                                                                   self.embedding_dim_1) if len(\n",
    "            belongs_to_collection_x_0.shape) > 1 else belongs_to_collection_x_0.view(1, 1, self.embedding_dim_1)\n",
    "        belongs_to_collection_x_lstm, _ = self.lstm_1(belongs_to_collection_x_0, (h0_1, c0_1))\n",
    "\n",
    "        belongs_to_collection_out = self.relu_1_1(self.fc1_1(self.relu_0_1(self.fc0_1(belongs_to_collection_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "\n",
    "        original_language_x_0 = original_language_x_0.view(1, original_language_x_0.size()[0],\n",
    "                                                           self.embedding_dim_2) if len(\n",
    "            original_language_x_0.shape) > 1 else original_language_x_0.view(1, 1, self.embedding_dim_2)\n",
    "        original_language_x_lstm, _ = self.lstm_2(original_language_x_0, (h0_2, c0_2))\n",
    "\n",
    "        original_language_out = self.relu_1_2(self.fc1_2(self.relu_0_2(self.fc0_2(original_language_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "\n",
    "        original_title_x_0 = original_title_x_0.view(1, original_title_x_0.size()[0], self.embedding_dim_3) if len(\n",
    "            original_title_x_0.shape) > 1 else original_title_x_0.view(1, 1, self.embedding_dim_3)\n",
    "        original_title_x_lstm, _ = self.lstm_3(original_title_x_0, (h0_3, c0_3))\n",
    "\n",
    "        original_title_out = self.relu_1_3(self.fc1_3(self.relu_0_3(self.fc0_3(original_title_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "\n",
    "        if len(overview_x_0.shape) > 1:\n",
    "            overview_x_0 = overview_x_0.view(1, overview_x_0.size()[0], self.embedding_dim_4)\n",
    "        else:\n",
    "            overview_x_0 = overview_x_0.view(1, 1, self.embedding_dim_4)\n",
    "        overview_x_lstm, _ = self.lstm_4(overview_x_0, (h0_4, c0_4))\n",
    "\n",
    "        overview_out = self.relu_1_4(self.fc1_4(self.relu_0_4(self.fc0_4(overview_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "        if len(production_companies_x_0.shape) > 1:\n",
    "            production_companies_x_0 = production_companies_x_0.view(1, production_companies_x_0.size()[0],\n",
    "                                                                     self.embedding_dim_5)\n",
    "        else:\n",
    "            production_companies_x_0 = production_companies_x_0.view(1, 1, self.embedding_dim_5)\n",
    "        production_companies_x_lstm, _ = self.lstm_5(production_companies_x_0, (h0_5, c0_5))\n",
    "\n",
    "        production_companies_out = self.relu_1_5(self.fc1_5(self.relu_0_5(self.fc0_5(production_companies_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "        production_countries_x_0 = production_countries_x_0.view(1, production_countries_x_0.size()[0],\n",
    "                                                                 self.embedding_dim_6) if len(\n",
    "            production_countries_x_0.shape) > 1 else production_countries_x_0.view(1, 1,\n",
    "                                                                                   self.embedding_dim_6)\n",
    "        production_countries_x_lstm, _ = self.lstm_6(production_countries_x_0, (h0_6, c0_6))\n",
    "\n",
    "        production_countries_out = self.relu_1_6(self.fc1_6(self.relu_0_6(self.fc0_6(production_countries_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "        release_date_x_0 = release_date_x_0.view(1, release_date_x_0.size()[0], self.embedding_dim_7) if len(\n",
    "            release_date_x_0.shape) > 1 else release_date_x_0.view(1, 1, self.embedding_dim_7)\n",
    "\n",
    "        release_date_x_lstm, _ = self.lstm_7(release_date_x_0, (h0_7, c0_7))\n",
    "\n",
    "        release_date_out = self.relu_1_7(self.fc1_7(self.relu_0_7(self.fc0_7(release_date_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "        spoken_languages_x_0 = spoken_languages_x_0.view(1, spoken_languages_x_0.size()[0],\n",
    "                                                         self.embedding_dim_8) if len(\n",
    "            spoken_languages_x_0.shape) > 1 else spoken_languages_x_0.view(1, 1, self.embedding_dim_8)\n",
    "\n",
    "        spoken_languages_x_lstm, _ = self.lstm_8(spoken_languages_x_0, (h0_8, c0_8))\n",
    "\n",
    "        spoken_languages_out = self.relu_1_8(self.fc1_8(self.relu_0_8(self.fc0_8(spoken_languages_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "\n",
    "        tagline_x_0 = tagline_x_0.view(1, 1, self.embedding_dim_9) if len(tagline_x_0.shape) == 1 else tagline_x_0.view(\n",
    "            1, tagline_x_0.size()[0], self.embedding_dim_9)\n",
    "\n",
    "        tagline_x_lstm, _ = self.lstm_9(tagline_x_0, (h0_9, c0_9))\n",
    "\n",
    "        tagline_out = self.relu_1_9(self.fc1_9(self.relu_0_9(self.fc0_9(tagline_x_lstm))))\n",
    "\n",
    "        # OverflowError\n",
    "        title_x_0 = title_x_0.view(1, title_x_0.size()[0], self.embedding_dim_10) if len(\n",
    "            title_x_0.shape) > 1 else title_x_0.view(1, 1, self.embedding_dim_10)\n",
    "        title_x_lstm, _ = self.lstm_10(title_x_0, (h0_10, c0_10))\n",
    "\n",
    "        title_out = self.relu_1_10(self.fc1_10(self.relu_0_10(self.fc0_10(title_x_lstm))))\n",
    "\n",
    "        x_1 = torch.cat((belongs_to_collection_out,\n",
    "                         original_language_out,\n",
    "                         original_title_out,\n",
    "                         overview_out,\n",
    "                         production_companies_out,\n",
    "                         production_countries_out,\n",
    "                         release_date_out,\n",
    "                         spoken_languages_out,\n",
    "                         tagline_out,\n",
    "                         title_out), dim=1)\n",
    "        non_text = non_text.view(1, 1, -1)\n",
    "        x_2 = torch.cat((x_1, non_text), dim=1)\n",
    "        prediction = self.softmax(self.output_layer(x_2))\n",
    "\n",
    "        return prediction\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def train(data_loader, epochs: int = 50):\n",
    "    scalar = torch.cuda.amp.GradScaler()\n",
    "    network = Net().to(DEVICE)\n",
    "    loss_function = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=3e-4)\n",
    "\n",
    "    print('Initials Function')\n",
    "    for epoch in range(epochs):\n",
    "        accurate = 0\n",
    "        not_accurate = 0\n",
    "        total_loss = 0\n",
    "        print(f'Running on Epoch {epoch + 1} / {epochs}', end='\\r')\n",
    "        for index, (x, y) in enumerate(data_loader.dataset):\n",
    "            if DEVICE == 'cuda':\n",
    "                optimizer.zero_grad()\n",
    "                adult_x = torch.from_numpy(x['adult']).type(torch.cuda.FloatTensor)\n",
    "                belongs_to_collection_x = torch.from_numpy(x['belongs_to_collection']).type(torch.cuda.IntTensor)\n",
    "                budget_x = torch.from_numpy(x['budget'].reshape(1, 1)).type(torch.cuda.FloatTensor)\n",
    "                original_language_x = torch.from_numpy(x['original_language']).type(torch.cuda.IntTensor)\n",
    "                original_title_x = torch.from_numpy(x['original_title']).type(torch.cuda.IntTensor)\n",
    "                overview_x = torch.from_numpy(x['overview']).type(torch.cuda.IntTensor)\n",
    "                popularity_x = torch.from_numpy(x['popularity'].reshape(1, 1)).type(torch.cuda.FloatTensor)\n",
    "                production_companies_x = torch.from_numpy(x['production_companies']).type(torch.cuda.IntTensor)\n",
    "                production_countries_x = torch.from_numpy(x['production_countries']).type(torch.cuda.IntTensor)\n",
    "                release_date_x = torch.from_numpy(x['release_date']).type(torch.cuda.IntTensor)\n",
    "                revenue_x = torch.from_numpy(x['revenue']).type(torch.cuda.FloatTensor)\n",
    "                runtime_x = torch.from_numpy(x['runtime'].reshape(1, 1)).type(torch.cuda.FloatTensor)\n",
    "                spoken_languages_x = torch.from_numpy(x['spoken_languages']).type(torch.cuda.IntTensor)\n",
    "                status_x = torch.from_numpy(x['status']).type(torch.cuda.FloatTensor)\n",
    "                tagline_x = torch.from_numpy(x['tagline']).type(torch.cuda.IntTensor)\n",
    "                title_x = torch.from_numpy(x['title']).type(torch.cuda.IntTensor)\n",
    "                video_x = torch.from_numpy(x['video']).type(torch.cuda.FloatTensor)\n",
    "                vote_average_x = torch.from_numpy(x['vote_average']).type(torch.cuda.FloatTensor)\n",
    "                vote_count_x = torch.from_numpy(x['vote_count']).type(torch.cuda.FloatTensor)\n",
    "                genres_y = torch.from_numpy(y['genres']).type(torch.cuda.IntTensor)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    y_hat = network.forward(adult=adult_x,\n",
    "                                            belongs_to_collection=belongs_to_collection_x,\n",
    "                                            budget=budget_x,\n",
    "                                            original_language=original_language_x,\n",
    "                                            original_title=original_title_x,\n",
    "                                            overview=overview_x,\n",
    "                                            popularity=popularity_x,\n",
    "                                            production_companies=production_companies_x,\n",
    "                                            production_countries=production_countries_x,\n",
    "                                            release_date=release_date_x,\n",
    "                                            runtime=runtime_x,\n",
    "                                            revenue=revenue_x,\n",
    "                                            spoken_languages=spoken_languages_x,\n",
    "                                            status=status_x,\n",
    "                                            tagline=tagline_x,\n",
    "                                            title=title_x,\n",
    "                                            video=video_x,\n",
    "                                            vote_average=vote_average_x\n",
    "                                            )\n",
    "                    simulation_y = torch.zeros(y_hat.shape).to(DEVICE)\n",
    "                    simulation_y[:, :, 0:] = genres_y\n",
    "                    loss = loss_function(simulation_y, y_hat).to(DEVICE)\n",
    "                del adult_x\n",
    "                del belongs_to_collection_x\n",
    "                del budget_x\n",
    "                del original_language_x\n",
    "                del original_title_x\n",
    "                del overview_x\n",
    "                del popularity_x\n",
    "                del production_companies_x\n",
    "                del production_countries_x\n",
    "                del release_date_x\n",
    "                del revenue_x\n",
    "                del runtime_x\n",
    "                del spoken_languages_x\n",
    "                del status_x\n",
    "                del tagline_x\n",
    "                del title_x\n",
    "                del video_x\n",
    "                del vote_average_x\n",
    "                del vote_count_x\n",
    "                scalar.scale(loss).backward()\n",
    "                scalar.step(optimizer)\n",
    "                scalar.update()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                if y_hat[:, :, 0:] == simulation_y[:, :, 0:]:\n",
    "                    accurate += 1\n",
    "                else:\n",
    "                    not_accurate += 1\n",
    "                ac = round((accurate / index) * 100, 2)\n",
    "                print(\n",
    "                    f'epoch {epoch} / {epochs} , index : {index} accuracy : {ac} loss : {round(total_loss, 3)} , pass : {round((index / dsm.__len__()) * 100, 3)}',\n",
    "                    end='\\r')\n",
    "\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                adult_x = torch.from_numpy(x['adult']).type(torch.FloatTensor)\n",
    "                belongs_to_collection_x = torch.from_numpy(x['belongs_to_collection']).type(torch.IntTensor)\n",
    "                budget_x = torch.from_numpy(x['budget'].reshape(1, 1)).type(torch.FloatTensor)\n",
    "                original_language_x = torch.from_numpy(x['original_language']).type(torch.IntTensor)\n",
    "                original_title_x = torch.from_numpy(x['original_title']).type(torch.IntTensor)\n",
    "                overview_x = torch.from_numpy(x['overview']).type(torch.IntTensor)\n",
    "                popularity_x = torch.from_numpy(x['popularity'].reshape(1, 1)).type(torch.FloatTensor)\n",
    "                production_companies_x = torch.from_numpy(x['production_companies']).type(torch.IntTensor)\n",
    "                production_countries_x = torch.from_numpy(x['production_countries']).type(torch.IntTensor)\n",
    "                release_date_x = torch.from_numpy(x['release_date']).type(torch.IntTensor)\n",
    "                revenue_x = torch.from_numpy(x['revenue']).type(torch.FloatTensor)\n",
    "                runtime_x = torch.from_numpy(x['runtime'].reshape(1, 1)).type(torch.FloatTensor)\n",
    "                spoken_languages_x = torch.from_numpy(x['spoken_languages']).type(torch.IntTensor)\n",
    "                status_x = torch.from_numpy(x['status']).type(torch.FloatTensor)\n",
    "                tagline_x = torch.from_numpy(x['tagline']).type(torch.IntTensor)\n",
    "                title_x = torch.from_numpy(x['title']).type(torch.IntTensor)\n",
    "                video_x = torch.from_numpy(x['video']).type(torch.FloatTensor)\n",
    "                vote_average_x = torch.from_numpy(x['vote_average']).type(torch.FloatTensor)\n",
    "                vote_count_x = torch.from_numpy(x['vote_count']).type(torch.FloatTensor)\n",
    "                genres_y = torch.from_numpy(y['genres']).type(torch.IntTensor)\n",
    "                y_hat = network.forward(adult=adult_x,\n",
    "                                        belongs_to_collection=belongs_to_collection_x,\n",
    "                                        budget=budget_x,\n",
    "                                        original_language=original_language_x,\n",
    "                                        original_title=original_title_x,\n",
    "                                        overview=overview_x,\n",
    "                                        popularity=popularity_x,\n",
    "                                        production_companies=production_companies_x,\n",
    "                                        production_countries=production_countries_x,\n",
    "                                        release_date=release_date_x,\n",
    "                                        runtime=runtime_x,\n",
    "                                        revenue=revenue_x,\n",
    "                                        spoken_languages=spoken_languages_x,\n",
    "                                        status=status_x,\n",
    "                                        tagline=tagline_x,\n",
    "                                        title=title_x,\n",
    "                                        video=video_x,\n",
    "                                        vote_average=vote_average_x\n",
    "                                        )\n",
    "\n",
    "                del adult_x\n",
    "                del belongs_to_collection_x\n",
    "                del budget_x\n",
    "                del original_language_x\n",
    "                del original_title_x\n",
    "                del overview_x\n",
    "                del popularity_x\n",
    "                del production_companies_x\n",
    "                del production_countries_x\n",
    "                del release_date_x\n",
    "                del revenue_x\n",
    "                del runtime_x\n",
    "                del spoken_languages_x\n",
    "                del status_x\n",
    "                del tagline_x\n",
    "                del title_x\n",
    "                del video_x\n",
    "                del vote_average_x\n",
    "                del vote_count_x\n",
    "\n",
    "                simulation_y = torch.zeros(y_hat.shape).to(DEVICE)\n",
    "                simulation_y[:, :, 0:] = genres_y\n",
    "                loss = loss_function(simulation_y, y_hat).to(DEVICE)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                if y_hat[:, :, 0:] == simulation_y[:, :, 0:]:\n",
    "                    accurate += 1\n",
    "                else:\n",
    "                    not_accurate += 1\n",
    "                ac = round((accurate / index) * 100, 2)\n",
    "                print(\n",
    "                    f'epoch {epoch} / {epochs} , index : {index} accuracy : {ac} loss : {round(total_loss, 3)} , pass : {round((index / dsm.__len__()) * 100, 3)}',\n",
    "                    end='\\r')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;255;0;0initialization Done\u001B[38;2;255;255;255m\n",
      "Initials Function\n",
      "Running on Epoch 1 / 50\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 800000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/447130370.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_loader\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdataLd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14984/3517859641.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(data_loader, epochs)\u001B[0m\n\u001B[0;32m    115\u001B[0m                 \u001B[0msimulation_y\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgenres_y\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msimulation_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_hat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDEVICE\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 117\u001B[1;33m                 \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    118\u001B[0m                 \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Conda\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    361\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    362\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 363\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    365\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Conda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    171\u001B[0m     \u001B[1;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    172\u001B[0m     \u001B[1;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 173\u001B[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[0;32m    174\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    175\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 800000000 bytes."
     ]
    }
   ],
   "source": [
    "train(data_loader=dataLd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(dsm.__len__())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(dsm.adult[dsm.__len__()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}