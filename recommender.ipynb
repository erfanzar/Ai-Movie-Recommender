{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import ast\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   adult                              belongs_to_collection    budget  \\\n0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n1  False                                                NaN  65000000   \n2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n3  False                                                NaN  16000000   \n4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n\n                                              genres  \\\n0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n4                     [{'id': 35, 'name': 'Comedy'}]   \n\n                               homepage     id    imdb_id original_language  \\\n0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n1                                   NaN   8844  tt0113497                en   \n2                                   NaN  15602  tt0113228                en   \n3                                   NaN  31357  tt0114885                en   \n4                                   NaN  11862  tt0113041                en   \n\n                original_title  \\\n0                    Toy Story   \n1                      Jumanji   \n2             Grumpier Old Men   \n3            Waiting to Exhale   \n4  Father of the Bride Part II   \n\n                                            overview  ... release_date  \\\n0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n\n       revenue runtime                                   spoken_languages  \\\n0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n\n     status                                            tagline  \\\n0  Released                                                NaN   \n1  Released          Roll the dice and unleash the excitement!   \n2  Released  Still Yelling. Still Fighting. Still Ready for...   \n3  Released  Friends are the people who let you be yourself...   \n4  Released  Just When His World Is Back To Normal... He's ...   \n\n                         title  video vote_average vote_count  \n0                    Toy Story  False          7.7     5415.0  \n1                      Jumanji  False          6.9     2413.0  \n2             Grumpier Old Men  False          6.5       92.0  \n3            Waiting to Exhale  False          6.1       34.0  \n4  Father of the Bride Part II  False          5.7      173.0  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adult</th>\n      <th>belongs_to_collection</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>id</th>\n      <th>imdb_id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>...</th>\n      <th>release_date</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>video</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n      <td>30000000</td>\n      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n      <td>http://toystory.disney.com/toy-story</td>\n      <td>862</td>\n      <td>tt0114709</td>\n      <td>en</td>\n      <td>Toy Story</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>...</td>\n      <td>1995-10-30</td>\n      <td>373554033.0</td>\n      <td>81.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>NaN</td>\n      <td>Toy Story</td>\n      <td>False</td>\n      <td>7.7</td>\n      <td>5415.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>NaN</td>\n      <td>65000000</td>\n      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n      <td>NaN</td>\n      <td>8844</td>\n      <td>tt0113497</td>\n      <td>en</td>\n      <td>Jumanji</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>...</td>\n      <td>1995-12-15</td>\n      <td>262797249.0</td>\n      <td>104.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n      <td>Released</td>\n      <td>Roll the dice and unleash the excitement!</td>\n      <td>Jumanji</td>\n      <td>False</td>\n      <td>6.9</td>\n      <td>2413.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n      <td>0</td>\n      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n      <td>NaN</td>\n      <td>15602</td>\n      <td>tt0113228</td>\n      <td>en</td>\n      <td>Grumpier Old Men</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>...</td>\n      <td>1995-12-22</td>\n      <td>0.0</td>\n      <td>101.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n      <td>Grumpier Old Men</td>\n      <td>False</td>\n      <td>6.5</td>\n      <td>92.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>NaN</td>\n      <td>16000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n      <td>NaN</td>\n      <td>31357</td>\n      <td>tt0114885</td>\n      <td>en</td>\n      <td>Waiting to Exhale</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>...</td>\n      <td>1995-12-22</td>\n      <td>81452156.0</td>\n      <td>127.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Friends are the people who let you be yourself...</td>\n      <td>Waiting to Exhale</td>\n      <td>False</td>\n      <td>6.1</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n      <td>0</td>\n      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n      <td>NaN</td>\n      <td>11862</td>\n      <td>tt0113041</td>\n      <td>en</td>\n      <td>Father of the Bride Part II</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>...</td>\n      <td>1995-02-10</td>\n      <td>76578911.0</td>\n      <td>106.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Just When His World Is Back To Normal... He's ...</td>\n      <td>Father of the Bride Part II</td>\n      <td>False</td>\n      <td>5.7</td>\n      <td>173.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
    "data_csv.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_csv = data_csv.drop('imdb_id', axis=1)\n",
    "data_csv = data_csv.drop('id', axis=1)\n",
    "data_csv = data_csv.drop('poster_path', axis=1)\n",
    "data_csv = data_csv.drop('homepage', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['adult', 'belongs_to_collection', 'budget', 'genres',\n       'original_language', 'original_title', 'overview', 'popularity',\n       'production_companies', 'production_countries', 'release_date',\n       'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title',\n       'video', 'vote_average', 'vote_count'],\n      dtype='object')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class DataSetManual(Dataset):\n",
    "    def __init__(self, data, vocab: dict = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if vocab is not None:\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            self.vocab = {}\n",
    "\n",
    "        self.categories = {}\n",
    "        self.adult = data['adult']\n",
    "        self.belongs_to_collection = data['belongs_to_collection']\n",
    "        self.budget = data['budget']\n",
    "        self.genres = data['genres']\n",
    "        self.original_language = data['original_language']\n",
    "        self.original_title = data['original_title']\n",
    "        self.overview = data['overview']\n",
    "        self.popularity = data['popularity']\n",
    "        self.production_companies = data['production_companies']\n",
    "        self.production_countries = data['production_countries']\n",
    "        self.release_date = data['release_date']\n",
    "        self.revenue = data['revenue']\n",
    "        self.runtime = data['runtime']\n",
    "        self.spoken_languages = data['spoken_languages']\n",
    "        self.status = data['status']\n",
    "        self.tagline = data['tagline']\n",
    "        self.tittle = data['title']\n",
    "        self.video = data['video']\n",
    "        self.vote_average = data['vote_average']\n",
    "        self.vote_count = data['vote_count']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adult) - 1\n",
    "\n",
    "    def __save_vocab__(self, name:str='vocab.yaml',path:'str'=None):\n",
    "        pbar = tqdm(range(self.__len__()))\n",
    "\n",
    "        rows = ['word' , 'ids']\n",
    "        if path is not None:\n",
    "            os.chdir(path)\n",
    "            pbar.set_description(f'path To {path}')\n",
    "        else:\n",
    "            path = os.getcwd()\n",
    "        for i in pbar:\n",
    "            _, _ = self.__getitem__(i)\n",
    "\n",
    "        if name.endswith('.yaml'):\n",
    "\n",
    "            with open(f'{path}{name}', 'w') as writer:\n",
    "                print(f'writing yaml file {name}')\n",
    "                print(f'at {path}{name}')\n",
    "                yaml.dump(self.vocab, writer)\n",
    "                print(f'Done')\n",
    "        if name.endswith('.json'):\n",
    "\n",
    "            pbar = tqdm(range(len(self.vocab)))\n",
    "            with open(f'{path}{name}','w') as write:\n",
    "                pbar.set_description(f'writing json file {name}')\n",
    "                pbar.set_description(f'at {path}{name}')\n",
    "                list_vocab = list(self.vocab)\n",
    "                list_filler = []\n",
    "                for i in pbar:\n",
    "                    key = list_vocab[i]\n",
    "                    val = self.vocab[key]\n",
    "                    list_filler.append({'key':key,'val':val})\n",
    "                jsoned = dict(list_filler)\n",
    "                json.dump(jsoned,write)\n",
    "                pbar.set_description(f'Done')\n",
    "\n",
    "    def translate(self, *arg: [dict, int, list]) -> str:\n",
    "        ...\n",
    "        simulation_list = list(self.vocab)\n",
    "        s_pr = []\n",
    "        arg = list(arg)\n",
    "\n",
    "        for i in range(len(arg)):\n",
    "\n",
    "            if isinstance(arg[i], int):\n",
    "                s_pr.append(simulation_list[arg[i]])\n",
    "            if isinstance(arg[i], list) or isinstance(arg[i], np.ndarray) or isinstance(arg[i], tuple):\n",
    "\n",
    "                for v in range(len(arg[i])):\n",
    "                    s_pr.append(simulation_list[int(arg[i][v])])\n",
    "        s_pr = str(s_pr)\n",
    "        s_pr = s_pr.replace(']', '')\n",
    "        s_pr = s_pr.replace('[', '')\n",
    "        s_pr = s_pr.replace(',', '')\n",
    "        s_pr = s_pr.replace(\"'\", '')\n",
    "        s_pr = s_pr.replace('\"', '')\n",
    "        return s_pr\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        #adult\n",
    "        item = int(item)\n",
    "        if 'nan' not in self.vocab:\n",
    "            self.vocab['nan'] = len(self.vocab)\n",
    "        b_point = []\n",
    "        if '^' not in self.vocab:\n",
    "            self.vocab['^'] = len(self.vocab)\n",
    "        b_point.append(self.vocab['^'])\n",
    "\n",
    "        adult_out = []\n",
    "        adult = self.adult[item].lower()\n",
    "        if adult not in self.vocab:\n",
    "            self.vocab[adult] = len(self.vocab)\n",
    "        adult_out.append(self.vocab[adult])\n",
    "\n",
    "        popularity_out = 0.\n",
    "        if isinstance(self.popularity[item], float) or isinstance(self.popularity[item], int):\n",
    "            popularity_out = float(self.popularity[item])\n",
    "        # belongs_to_collection\n",
    "        belongs_to_collection_out = []\n",
    "        if not isinstance(self.belongs_to_collection[item], float):\n",
    "\n",
    "            sim = str(self.belongs_to_collection[item])\n",
    "            sim = ast.literal_eval(sim)\n",
    "            if not isinstance(sim, float):\n",
    "                belongs_to_collection = sim['name'].lower().split()\n",
    "            else:\n",
    "                belongs_to_collection = 'nan'\n",
    "        else:\n",
    "            belongs_to_collection = ['nan']\n",
    "\n",
    "        for word in belongs_to_collection:\n",
    "            if word not in self.vocab:\n",
    "                self.vocab[word] = len(self.vocab)\n",
    "            belongs_to_collection_out.append(self.vocab[word])\n",
    "        belongs_to_collection_out.append(b_point[0])\n",
    "        genres_out = []\n",
    "        genres_names = []\n",
    "        genres_str = str(self.genres[item])\n",
    "        genres_json = ast.literal_eval(genres_str)\n",
    "        if self.genres[item] != 'nan':\n",
    "            for i in range(len(genres_json)):\n",
    "                genres_names.append(genres_json[i]['name'].lower())\n",
    "\n",
    "            for word in genres_names:\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                if word not in self.categories:\n",
    "                    self.categories[word] = len(self.categories)\n",
    "                genres_out.append(self.categories[word])\n",
    "        else:\n",
    "            genres_out = self.vocab['nan']\n",
    "        o_language_out = []\n",
    "        if self.original_language[item] != '[]' and not isinstance(self.original_language[item], float):\n",
    "            o_language = self.original_language[item]\n",
    "            o_language = o_language.lower().split()\n",
    "            if self.original_language[item] != 'nan':\n",
    "                for word in o_language:\n",
    "                    if word not in self.vocab:\n",
    "                        self.vocab[word] = len(self.vocab)\n",
    "                    o_language_out.append(self.vocab[word])\n",
    "        else:\n",
    "            o_language_out.append(self.vocab['nan'])\n",
    "        o_language_out.append(b_point[0])\n",
    "        budget_out = 0\n",
    "        if isinstance(self.budget[item], int) or isinstance(self.budget[item], float):\n",
    "            budget_out = int(self.budget[item])\n",
    "        else:\n",
    "            budget_out = 0\n",
    "        original_title_out = []\n",
    "        original_title = self.original_title[item]\n",
    "        original_title = original_title.lower().split()\n",
    "        if self.original_title[item] != 'nan':\n",
    "            for word in original_title:\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                original_title_out.append(self.vocab[word])\n",
    "        original_title_out.append(b_point[0])\n",
    "        overview_out = []\n",
    "        overview = self.overview[item]\n",
    "        if self.overview[item] != 'nan' and not isinstance(overview, float):\n",
    "\n",
    "            overview = overview.lower().split()\n",
    "            for word in overview:\n",
    "                gs = word.find('.')\n",
    "                if gs is not None:\n",
    "                    word = word.replace('.', '')\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                overview_out.append(self.vocab[word])\n",
    "\n",
    "        else:\n",
    "            overview_out.append(self.vocab['nan'])\n",
    "\n",
    "\n",
    "        production_companies_out = []\n",
    "        if not isinstance(self.production_companies[item], float):\n",
    "            if self.production_companies[item] != '[]' and len(self.production_companies[item]) != 0:\n",
    "\n",
    "                production_companies = str(self.production_companies[item])\n",
    "                production_companies = ast.literal_eval(production_companies)\n",
    "                if not isinstance(production_companies, bool):\n",
    "                    if len(production_companies) > 1:\n",
    "                        for i in range(len(production_companies)):\n",
    "                            spa = production_companies[i]['name'].lower().split()\n",
    "                            for word in spa:\n",
    "                                gs = word.find('.')\n",
    "                                if gs is not None:\n",
    "                                    word = word.replace('.', '')\n",
    "                                if word not in self.vocab:\n",
    "                                    self.vocab[word] = len(self.vocab)\n",
    "                                production_companies_out.append(self.vocab[word])\n",
    "                    else:\n",
    "                        spa = production_companies[0]['name'].lower().split()\n",
    "                        for word in spa:\n",
    "                            gs = word.find('.')\n",
    "                            if gs is not None:\n",
    "                                word = word.replace('.', '')\n",
    "                            if word not in self.vocab:\n",
    "                                self.vocab[word] = len(self.vocab)\n",
    "                            production_companies_out.append(self.vocab[word])\n",
    "                else:\n",
    "                    production_companies_out.append(self.vocab['nan'])\n",
    "            else:\n",
    "                production_companies_out.append(self.vocab['nan'])\n",
    "        else:\n",
    "            production_companies_out.append(self.vocab['nan'])\n",
    "        production_companies_out.append(b_point[0])\n",
    "        production_countries_out = []\n",
    "        if self.production_countries[item] != 'nan' and not isinstance(self.production_countries[item], float):\n",
    "            production_countries = str(self.production_countries[item])\n",
    "\n",
    "            production_countries = ast.literal_eval(production_countries)\n",
    "            if not isinstance(production_countries, float):\n",
    "                if len(production_countries) != 0:\n",
    "                    for i in range(len(production_countries)):\n",
    "                        spa = production_countries[i]['name'].lower().split()\n",
    "\n",
    "                        for word in spa:\n",
    "                            gs = word.find('.')\n",
    "                            if gs is not None:\n",
    "                                word = word.replace('.', '')\n",
    "                            if word not in self.vocab:\n",
    "                                self.vocab[word] = len(self.vocab)\n",
    "                            production_countries_out.append(self.vocab[word])\n",
    "            else:\n",
    "                production_countries_out.append(self.vocab['nan'])\n",
    "        else:\n",
    "            production_countries_out.append(self.vocab['nan'])\n",
    "        production_countries_out.append(b_point[0])\n",
    "        release_date_out = []\n",
    "        if self.release_date[item] != 'nan' and not isinstance(self.release_date[item], float):\n",
    "            release_date = self.release_date[item]\n",
    "            release_date = release_date.lower()\n",
    "            release_date = release_date.replace('-', '')\n",
    "            release_date_out.append(int(release_date))\n",
    "        else:\n",
    "            release_date_out = 00000000\n",
    "\n",
    "        revenue_out = []\n",
    "        revenue = self.revenue[item]\n",
    "        revenue_out.append(revenue)\n",
    "\n",
    "        spoken_languages_out = []\n",
    "        if self.spoken_languages[item] != 'nan' and not isinstance(self.spoken_languages[item], float):\n",
    "            spoken_languages = str(self.spoken_languages[item])\n",
    "            spoken_languages = ast.literal_eval(spoken_languages)\n",
    "            for i in range(len(spoken_languages)):\n",
    "                spa = spoken_languages[i]['name'].lower().split()\n",
    "                for word in spa:\n",
    "                    gs = word.find('.')\n",
    "                    if gs is not None:\n",
    "                        word = word.replace('.', '')\n",
    "                    if word not in self.vocab:\n",
    "                        self.vocab[word] = len(self.vocab)\n",
    "                    spoken_languages_out.append(self.vocab[word])\n",
    "        else:\n",
    "            spoken_languages_out.append(self.vocab['nan'])\n",
    "        spoken_languages_out.append(b_point[0])\n",
    "        status_out = []\n",
    "        if self.status[item] != 'nan' and not isinstance(self.status[item], float):\n",
    "            status = self.status[item]\n",
    "            status = status.lower().split()\n",
    "            for word in status:\n",
    "                gs = word.find('.')\n",
    "                if gs is not None:\n",
    "                    word = word.replace('.', '')\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                status_out.append(self.vocab[word])\n",
    "        else:\n",
    "            status_out = self.vocab['nan']\n",
    "        tagline_out = []\n",
    "\n",
    "        if self.tagline[item] != 'nan':\n",
    "            tagline = 0\n",
    "        else:\n",
    "            tagline = self.tagline[item]\n",
    "\n",
    "        # tagline = self.tagline[item] if self.tagline[item] != 'nan' else 0\n",
    "\n",
    "        tagline = str(tagline)\n",
    "        tagline_out.append(tagline)\n",
    "\n",
    "        title_out = []\n",
    "        tittle = self.tittle[item]\n",
    "        if self.tittle[item] != 'nan' and not isinstance(self.tittle[item], float):\n",
    "            tittle = tittle.lower().split()\n",
    "            for word in tittle:\n",
    "                gs = word.find('.')\n",
    "                if gs is not None:\n",
    "                    word = word.replace('.', '')\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab)\n",
    "                title_out.append(self.vocab[word])\n",
    "        else:\n",
    "            title_out.append(self.vocab['nan'])\n",
    "        title_out.append(b_point[0])\n",
    "        video_out = []\n",
    "        video = str(self.video[item])\n",
    "        video = video.lower().split()\n",
    "        for word in video:\n",
    "            gs = word.find('.')\n",
    "            if gs is not None:\n",
    "                word = word.replace('.', '')\n",
    "            if word not in self.vocab:\n",
    "                self.vocab[word] = len(self.vocab)\n",
    "            video_out.append(self.vocab[word])\n",
    "\n",
    "        vote_average_out = []\n",
    "        vote_average = self.vote_average[item]\n",
    "        vote_average_out.append(vote_average)\n",
    "\n",
    "        vote_count_out = []\n",
    "        vote_count = self.vote_count[item]\n",
    "        vote_count_out.append(vote_count)\n",
    "        if isinstance(status_out, list):\n",
    "            status_out = status_out[0]\n",
    "        elif isinstance(status_out, int):\n",
    "            status_out = status_out\n",
    "\n",
    "        nl_1 = np.concatenate((belongs_to_collection_out, title_out,original_title_out))\n",
    "        nl_1 = nl_1.astype(np.int8)\n",
    "\n",
    "        nl_2 = np.array(overview_out)\n",
    "        nl_2 = nl_2.astype(np.int8)\n",
    "\n",
    "        nl_3 = np.concatenate(( tagline_out,spoken_languages_out, o_language_out))\n",
    "        nl_3 = nl_3.astype(np.int8)\n",
    "\n",
    "        nl_4 = np.concatenate((production_companies_out,production_countries_out))\n",
    "        nl_4 = nl_4.astype(np.int8)\n",
    "\n",
    "        outputs = {\n",
    "            'nl_1': nl_1,\n",
    "            'nl_2': nl_2,\n",
    "            'nl_3': nl_3,\n",
    "            'nl_4': nl_4,\n",
    "            'adult': np.array(adult_out, dtype=np.float64),\n",
    "            'budget': np.array(budget_out, dtype=np.float64),\n",
    "            'popularity': np.array(popularity_out, dtype=np.float64),\n",
    "            'release_date': np.array(release_date_out, dtype=np.float64),\n",
    "            'revenue': np.array(revenue_out, dtype=np.float64),\n",
    "            'runtime': np.array(self.runtime[item], dtype=np.float64),\n",
    "            'status': np.array(status_out, dtype=np.float64),\n",
    "            'video': np.array(video_out, dtype=np.float64),\n",
    "            'vote_average': np.array(vote_average_out, dtype=np.float64),\n",
    "            'vote_count': np.array(vote_count_out, dtype=np.float64),\n",
    "        }\n",
    "\n",
    "        cfk = np.zeros(32, dtype=np.float64)\n",
    "\n",
    "        for i in range(len(genres_out)):\n",
    "            cfk[genres_out[i]] = 1\n",
    "\n",
    "        targets = {\n",
    "            'genres': cfk,\n",
    "        }\n",
    "\n",
    "        return outputs, targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "path To E:/Python/movie_recommender/: 100%|██████████| 45465/45465 [00:11<00:00, 3908.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing yaml file vocab.yaml\n",
      "at E:/Python/movie_recommender/vocab.yaml\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "dsm = DataSetManual(data_csv)\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE = 'cpu'\n",
    "# DEVICE = 'cuda:0'\n",
    "dsm.__save_vocab__('vocab.yaml',path='E:/Python/movie_recommender/')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dataLd = DataLoader(\n",
    "    dsm,\n",
    "    batch_size=4,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_embedding_1: int = 171678+10,\n",
    "                 embedding_dim_1: int = 400,\n",
    "                 num_embedding_2: int = 171678+10,\n",
    "                 embedding_dim_2: int = 400,\n",
    "                 num_embedding_3: int = 171678+10,\n",
    "                 embedding_dim_3: int = 400,\n",
    "                 num_embedding_4: int = 171678+10,\n",
    "                 embedding_dim_4: int = 400,\n",
    "                 lstm_layers_1: int = 1,\n",
    "                 lstm_hidden_num_1: int = 90,\n",
    "                 lstm_layers_2: int = 1,\n",
    "                 lstm_hidden_num_2: int = 90,\n",
    "                 lstm_layers_3: int = 1,\n",
    "                 lstm_hidden_num_3: int = 90,\n",
    "                 lstm_layers_4: int = 1,\n",
    "                 lstm_hidden_num_4: int = 90,\n",
    "\n",
    "                 output_size: int = 15):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.num_embedding_1 = num_embedding_1\n",
    "        self.embedding_dim_1 = embedding_dim_1\n",
    "\n",
    "        self.lstm_hidden_num_1 = lstm_hidden_num_1\n",
    "\n",
    "        self.lstm_layers_1 = lstm_layers_1\n",
    "\n",
    "        self.fc_adult_0 = nn.Linear(1, 15)\n",
    "        self.fc_adult_1 = nn.Linear(15, 10)\n",
    "\n",
    "        self.fc_budget_0 = nn.Linear(1, 10)\n",
    "        self.fc_budget_1 = nn.Linear(10, 10)\n",
    "\n",
    "        self.fc_popularity_0 = nn.Linear(1, 15)\n",
    "        self.fc_popularity_1 = nn.Linear(15, 10)\n",
    "\n",
    "        self.fc_revenue_0 = nn.Linear(1, 30)\n",
    "        self.fc_revenue_1 = nn.Linear(30, 10)\n",
    "\n",
    "        self.fc_runtime_0 = nn.Linear(1, 15)\n",
    "        self.fc_runtime_1 = nn.Linear(15, 10)\n",
    "\n",
    "        self.fc_status_0 = nn.Linear(1, 20)\n",
    "        self.fc_status_1 = nn.Linear(20, 10)\n",
    "\n",
    "        self.fc_video_0 = nn.Linear(1, 20)\n",
    "        self.fc_video_1 = nn.Linear(20, 10)\n",
    "\n",
    "        self.fc_vote_average_0 = nn.Linear(1, 15)\n",
    "        self.fc_vote_average_1 = nn.Linear(15, 10)\n",
    "\n",
    "        self.fc_vote_count_0 = nn.Linear(1, 15)\n",
    "        self.fc_vote_count_1 = nn.Linear(15, 10)\n",
    "\n",
    "        self.fc_release_date_0 = nn.Linear(1, 15)\n",
    "        self.fc_release_date_1 = nn.Linear(15, 10)\n",
    "\n",
    "        self.embedding_layer_1 = nn.Embedding(num_embeddings=num_embedding_1, embedding_dim=embedding_dim_1)\n",
    "        self.lstm_1 = nn.LSTM(num_layers=lstm_layers_1, hidden_size=lstm_hidden_num_1, input_size=embedding_dim_1)\n",
    "\n",
    "        self.embedding_layer_2 = nn.Embedding(num_embeddings=num_embedding_2, embedding_dim=embedding_dim_2)\n",
    "        self.lstm_2 = nn.LSTM(num_layers=lstm_layers_2, hidden_size=lstm_hidden_num_2, input_size=embedding_dim_2)\n",
    "\n",
    "        self.embedding_layer_3 = nn.Embedding(num_embeddings=num_embedding_3, embedding_dim=embedding_dim_3)\n",
    "        self.lstm_3 = nn.LSTM(num_layers=lstm_layers_3, hidden_size=lstm_hidden_num_3, input_size=embedding_dim_3)\n",
    "\n",
    "        self.embedding_layer_4 = nn.Embedding(num_embeddings=num_embedding_4, embedding_dim=embedding_dim_4)\n",
    "        self.lstm_4 = nn.LSTM(num_layers=lstm_layers_4, hidden_size=lstm_hidden_num_4, input_size=embedding_dim_4)\n",
    "\n",
    "        self.fc0_1 = nn.Linear(lstm_hidden_num_1, lstm_hidden_num_1 * 2)\n",
    "        self.relu_0_1 = nn.ReLU()\n",
    "        self.fc1_1 = nn.Linear(lstm_hidden_num_1 * 2, 8)\n",
    "        self.relu_1_1 = nn.ReLU()\n",
    "\n",
    "        self.output_layer_1 = nn.Linear(self.lstm_hidden_num_1, self.lstm_hidden_num_1*2)\n",
    "        self.output_layer_2 = nn.Linear( self.lstm_hidden_num_1*2, 64)\n",
    "        self.output_layer_3 = nn.Linear(64, 32)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    @staticmethod\n",
    "    def reshape(ins,hidden_size:int=90):\n",
    "        if len(ins.shape) > 1:\n",
    "            h0 = torch.zeros(1, ins.size()[0], hidden_size)\n",
    "            c0 = torch.zeros(1, ins.size()[0], hidden_size)\n",
    "            ins = ins.view(1, ins.size()[0], ins.size()[1])\n",
    "\n",
    "        else:\n",
    "            h0 = torch.zeros(1, 1, hidden_size)\n",
    "            c0 = torch.zeros(1, 1, hidden_size)\n",
    "            ins = ins.view(1, 1, ins.size()[0])\n",
    "        return ins, h0, c0\n",
    "    @staticmethod\n",
    "    def review(ins, dim_check:int=1, dims=1):\n",
    "        if len(ins.shape) <= dim_check:\n",
    "\n",
    "            ins = ins.view(dims,-1)\n",
    "        return ins\n",
    "    def forward(self,\n",
    "                nl_1: torch.Tensor,\n",
    "                nl_2: torch.Tensor,\n",
    "                nl_3: torch.Tensor,\n",
    "                nl_4: torch.Tensor,\n",
    "                adult: torch.Tensor,\n",
    "                budget: torch.Tensor,\n",
    "                popularity: torch.Tensor,\n",
    "                release_date: torch.Tensor,\n",
    "                revenue: torch.Tensor,\n",
    "                runtime: torch.Tensor,\n",
    "                status: torch.Tensor,\n",
    "                video: torch.Tensor,\n",
    "                vote_average: torch.Tensor,\n",
    "\n",
    "                ) -> torch.Tensor:\n",
    "        ...\n",
    "\n",
    "        if len(status.shape) <= 1:\n",
    "            status = status.view(1, -1)\n",
    "\n",
    "        release_date_out = f.leaky_relu_(self.fc_release_date_1(f.leaky_relu_(self.fc_release_date_0(release_date),0.2)),0.2)\n",
    "        adult_out = f.leaky_relu_(self.fc_adult_1(f.leaky_relu_(self.fc_adult_0(adult),0.2)),0.2)\n",
    "        budget_out = f.leaky_relu_(self.fc_budget_1(f.leaky_relu_(self.fc_budget_0(budget),0.2)),0.2)\n",
    "        popularity_out = f.leaky_relu_(self.fc_popularity_1(f.leaky_relu_(self.fc_popularity_0(popularity),0.2)),0.2)\n",
    "        revenue_out = f.leaky_relu_(self.fc_revenue_1(f.leaky_relu_(self.fc_revenue_0(revenue),0.2)),0.2)\n",
    "        runtime_out = f.leaky_relu_(self.fc_runtime_1(f.leaky_relu_(self.fc_runtime_0(runtime),0.2)),0.2)\n",
    "        status_out = f.leaky_relu_(self.fc_status_1(f.leaky_relu_(self.fc_status_0(status),0.2)),0.2)\n",
    "        video_out = f.leaky_relu_(self.fc_video_1(f.leaky_relu_(self.fc_video_0(video),0.2)),0.2)\n",
    "        vote_average_out = f.leaky_relu_(self.fc_vote_average_1(f.leaky_relu_(self.fc_vote_average_0(vote_average),0.2)),0.2)\n",
    "\n",
    "\n",
    "        release_date_out = self.review(release_date_out)\n",
    "        adult_out = self.review(adult_out)\n",
    "        budget_out = self.review(budget_out)\n",
    "        popularity_out = self.review(popularity_out)\n",
    "        revenue_out = self.review(revenue_out)\n",
    "        runtime_out = self.review(runtime_out)\n",
    "        status_out = self.review(status_out)\n",
    "        video_out = self.review(video_out)\n",
    "        vote_average_out = self.review(vote_average_out)\n",
    "\n",
    "        non_text = torch.cat(\n",
    "            (release_date_out, adult_out, budget_out, popularity_out, revenue_out, runtime_out,\n",
    "             status_out,\n",
    "             video_out, vote_average_out),dim=1)\n",
    "\n",
    "        embedding_two_out = self.embedding_layer_2(nl_2)\n",
    "        embedding_one_out = self.embedding_layer_1(nl_1)\n",
    "        embedding_three_out = self.embedding_layer_3(nl_3)\n",
    "        embedding_four_out = self.embedding_layer_4(nl_4)\n",
    "\n",
    "        reshape_one_out, h0_0, c0_0 = self.reshape(ins=embedding_one_out)\n",
    "        lstm_out_1, _ = self.lstm_1(reshape_one_out, (h0_0, c0_0))\n",
    "\n",
    "        reshape_two_out, h0_0, c0_0 = self.reshape(ins=embedding_two_out)\n",
    "        lstm_out_2, _ = self.lstm_2(reshape_two_out, (h0_0, c0_0))\n",
    "\n",
    "        reshape_three_out, h0_0, c0_0 = self.reshape(ins=embedding_three_out)\n",
    "        lstm_out_3, _ = self.lstm_3(reshape_three_out, (h0_0, c0_0))\n",
    "\n",
    "        reshape_four_out, h0_0, c0_0 = self.reshape(ins=embedding_four_out)\n",
    "        lstm_out_4, _ = self.lstm_4(reshape_four_out, (h0_0, c0_0))\n",
    "\n",
    "        non_text = non_text.view(1, 1, -1)\n",
    "        x_2 = torch.cat((lstm_out_1,lstm_out_2,lstm_out_3 ,lstm_out_4,non_text), dim=1)\n",
    "        prediction = self.softmax(self.output_layer_3(f.leaky_relu_(self.output_layer_2(f.leaky_relu_(self.output_layer_1(x_2),0.2)),0.2)))\n",
    "\n",
    "        return prediction\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "network = Net().to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def train(\n",
    "        network_in,\n",
    "        epochs: int = 50,\n",
    "):\n",
    "    scalar = torch.cuda.amp.GradScaler()\n",
    "    loss_function = nn.NLLLoss().to(DEVICE)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=3e-4)\n",
    "    pbar = enumerate(dataLd.dataset)\n",
    "    pbar = tqdm(pbar)\n",
    "\n",
    "    tqdm.write('initialization Done')\n",
    "    for epoch in range(epochs):\n",
    "        accurate = 0\n",
    "        not_accurate = 0\n",
    "        total_loss = 0\n",
    "        for index, (x, y) in pbar:\n",
    "            if DEVICE == 'cuda':\n",
    "                optimizer.zero_grad()\n",
    "                adult_x = torch.from_numpy(x['adult']).type(torch.cuda.FloatTensor)\n",
    "                belongs_to_collection_x = torch.from_numpy(x['belongs_to_collection']).type(torch.cuda.IntTensor)\n",
    "                budget_x = torch.from_numpy(x['budget'].reshape(1, 1)).type(torch.cuda.FloatTensor)\n",
    "                original_language_x = torch.from_numpy(x['original_language']).type(torch.cuda.IntTensor)\n",
    "                original_title_x = torch.from_numpy(x['original_title']).type(torch.cuda.IntTensor)\n",
    "                overview_x = torch.from_numpy(x['overview']).type(torch.cuda.IntTensor)\n",
    "                popularity_x = torch.from_numpy(x['popularity'].reshape(1, 1)).type(torch.cuda.FloatTensor)\n",
    "                production_companies_x = torch.from_numpy(x['production_companies']).type(torch.cuda.IntTensor)\n",
    "                production_countries_x = torch.from_numpy(x['production_countries']).type(torch.cuda.IntTensor)\n",
    "                release_date_x = torch.from_numpy(x['release_date']).type(torch.cuda.IntTensor)\n",
    "                revenue_x = torch.from_numpy(x['revenue']).type(torch.cuda.FloatTensor)\n",
    "                runtime_x = torch.from_numpy(x['runtime'].reshape(1, 1)).type(torch.cuda.FloatTensor)\n",
    "                spoken_languages_x = torch.from_numpy(x['spoken_languages']).type(torch.cuda.IntTensor)\n",
    "                status_x = torch.from_numpy(x['status']).type(torch.cuda.FloatTensor)\n",
    "                tagline_x = torch.from_numpy(x['tagline']).type(torch.cuda.IntTensor)\n",
    "                title_x = torch.from_numpy(x['title']).type(torch.cuda.IntTensor)\n",
    "                video_x = torch.from_numpy(x['video']).type(torch.cuda.FloatTensor)\n",
    "                vote_average_x = torch.from_numpy(x['vote_average']).type(torch.cuda.FloatTensor)\n",
    "                vote_count_x = torch.from_numpy(x['vote_count']).type(torch.cuda.FloatTensor)\n",
    "                genres_y = torch.from_numpy(y['genres']).type(torch.cuda.IntTensor)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    y_hat = network_in.forward(adult=adult_x,\n",
    "                                            belongs_to_collection=belongs_to_collection_x,\n",
    "                                            budget=budget_x,\n",
    "                                            original_language=original_language_x,\n",
    "                                            original_title=original_title_x,\n",
    "                                            overview=overview_x,\n",
    "                                            popularity=popularity_x,\n",
    "                                            production_companies=production_companies_x,\n",
    "                                            production_countries=production_countries_x,\n",
    "                                            release_date=release_date_x,\n",
    "                                            runtime=runtime_x,\n",
    "                                            revenue=revenue_x,\n",
    "                                            spoken_languages=spoken_languages_x,\n",
    "                                            status=status_x,\n",
    "                                            tagline=tagline_x,\n",
    "                                            title=title_x,\n",
    "                                            video=video_x,\n",
    "                                            vote_average=vote_average_x\n",
    "                                            )\n",
    "                    simulation_y = torch.zeros(y_hat.shape).to(DEVICE)\n",
    "                    simulation_y[:, :, 0:] = genres_y\n",
    "                    loss = loss_function(y_hat, simulation_y).to(DEVICE)\n",
    "                del adult_x\n",
    "                del belongs_to_collection_x\n",
    "                del budget_x\n",
    "                del original_language_x\n",
    "                del original_title_x\n",
    "                del overview_x\n",
    "                del popularity_x\n",
    "                del production_companies_x\n",
    "                del production_countries_x\n",
    "                del release_date_x\n",
    "                del revenue_x\n",
    "                del runtime_x\n",
    "                del spoken_languages_x\n",
    "                del status_x\n",
    "                del tagline_x\n",
    "                del title_x\n",
    "                del video_x\n",
    "                del vote_average_x\n",
    "                del vote_count_x\n",
    "                scalar.scale(loss).backward()\n",
    "                scalar.step(optimizer)\n",
    "                scalar.update()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                if y_hat[:, :, 0:] == simulation_y[:, :, 0:]:\n",
    "                    accurate += 1\n",
    "                else:\n",
    "                    not_accurate += 1\n",
    "                ac = round((accurate / index) * 100, 2)\n",
    "                print(\n",
    "                    f'epoch {epoch} / {epochs} , index : {index} accuracy : {ac} loss : {round(total_loss, 3)} , pass : {round((index / dsm.__len__()) * 100, 3)}',\n",
    "                    end='\\r')\n",
    "\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                nl_2 = torch.from_numpy(x['nl_2']).type(torch.IntTensor)\n",
    "                nl_1 = torch.from_numpy(x['nl_1']).type(torch.IntTensor)\n",
    "                nl_3 = torch.from_numpy(x['nl_3']).type(torch.IntTensor)\n",
    "                nl_4 = torch.from_numpy(x['nl_4']).type(torch.IntTensor)\n",
    "                adult_x = torch.from_numpy(x['adult']).type(torch.FloatTensor)\n",
    "                budget_x = torch.from_numpy(x['budget'].reshape(1, 1)).type(torch.FloatTensor)\n",
    "                popularity_x = torch.from_numpy(x['popularity'].reshape(1, 1)).type(torch.FloatTensor)\n",
    "                release_date_x = torch.from_numpy(x['release_date']).type(torch.FloatTensor)\n",
    "                revenue_x = torch.from_numpy(x['revenue']).type(torch.FloatTensor)\n",
    "                runtime_x = torch.from_numpy(x['runtime'].reshape(1, 1)).type(torch.FloatTensor)\n",
    "                status_x = torch.from_numpy(x['status']).type(torch.FloatTensor)\n",
    "                video_x = torch.from_numpy(x['video']).type(torch.FloatTensor)\n",
    "                vote_average_x = torch.from_numpy(x['vote_average']).type(torch.FloatTensor)\n",
    "                genres_y = torch.from_numpy(y['genres']).type(torch.IntTensor)\n",
    "                print(torch.max(nl_2))\n",
    "                print(nl_2.size())\n",
    "                y_hat = network_in.forward(\n",
    "                    nl_1=nl_1,\n",
    "                    nl_2=nl_2,\n",
    "                    nl_3=nl_3,\n",
    "                    nl_4=nl_4,\n",
    "                    adult=adult_x,\n",
    "                    budget=budget_x,\n",
    "                    popularity=popularity_x,\n",
    "                    release_date=release_date_x,\n",
    "                    runtime=runtime_x,\n",
    "                    revenue=revenue_x,\n",
    "                    status=status_x,\n",
    "                    video=video_x,\n",
    "                    vote_average=vote_average_x\n",
    "                )\n",
    "                del adult_x\n",
    "                del budget_x\n",
    "                del release_date_x\n",
    "                del revenue_x\n",
    "                del runtime_x\n",
    "                del status_x\n",
    "                del video_x\n",
    "                del vote_average_x\n",
    "\n",
    "                simulation_y = torch.zeros(1, 32).to(DEVICE)\n",
    "                simulation_y[0, 0:] = genres_y\n",
    "\n",
    "                loss = loss_function(y_hat, simulation_y.type(torch.LongTensor)).to(DEVICE)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                tza = []\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                y_hat_fr = y_hat[:, 0]\n",
    "                y_hat_numpy = y_hat_fr.detach().numpy()\n",
    "                simulation_y_numpy = simulation_y.detach().numpy()\n",
    "                for i in range(y_hat_numpy[0].shape[0]):\n",
    "                    tza.append(0 if y_hat_numpy[0, i] < 0.5 else 1)\n",
    "                simulation_y_numpy = simulation_y_numpy.astype(np.int8)\n",
    "                accurate_num = 0\n",
    "                for i in range(simulation_y_numpy.shape[1]):\n",
    "                    ova = simulation_y_numpy[0, i]\n",
    "                    if tza[i] == ova:\n",
    "                        accurate_num += 1\n",
    "                accurate += 1 if accurate_num == 32 else 0\n",
    "                not_accurate += 0 if accurate_num == 32 else 1\n",
    "\n",
    "                del simulation_y_numpy\n",
    "                del y_hat_numpy\n",
    "                del y_hat_fr\n",
    "                del tza\n",
    "\n",
    "                ac = (accurate / index) * 100 if accurate != 0 else 0\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f' \\r epoch {epoch} / {epochs} loss : {loss.item():.4f}  loss_total : {total_loss:.4f} , pass : % {(index / dsm.__len__()) * 100:.4f} , ac : {ac:.4f}'\n",
    "                )\n",
    "\n",
    "                pbar.refresh()\n",
    "        pbar.write('')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization Done\n",
      "tensor(50, dtype=torch.int32)\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch 0 / 50 loss : -0.0314  loss_total : -0.0314 , pass : % 0.0000 , ac : 0.0000: : 1it [00:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(112, dtype=torch.int32)\n",
      "torch.Size([67])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " epoch 0 / 50 loss : -0.0313  loss_total : -0.0627 , pass : % 0.0022 , ac : 0.0000: : 2it [00:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(127, dtype=torch.int32)\n",
      "torch.Size([56])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15980/3201688186.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15980/3998885867.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(network_in, epochs)\u001B[0m\n\u001B[0;32m    111\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnl_2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnl_2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 113\u001B[1;33m                 y_hat = network_in.forward(\n\u001B[0m\u001B[0;32m    114\u001B[0m                     \u001B[0mnl_1\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnl_1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m                     \u001B[0mnl_2\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnl_2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_15980/1088322682.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, nl_1, nl_2, nl_3, nl_4, adult, budget, popularity, release_date, revenue, runtime, status, video, vote_average)\u001B[0m\n\u001B[0;32m    146\u001B[0m              video_out, vote_average_out),dim=1)\n\u001B[0;32m    147\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 148\u001B[1;33m         \u001B[0membedding_two_out\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_layer_2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnl_2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    149\u001B[0m         \u001B[0membedding_one_out\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_layer_1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnl_1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    150\u001B[0m         \u001B[0membedding_three_out\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_layer_3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnl_3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Conda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1111\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Conda\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    157\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 158\u001B[1;33m         return F.embedding(\n\u001B[0m\u001B[0;32m    159\u001B[0m             \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpadding_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_norm\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    160\u001B[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001B[1;32mE:\\Conda\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2181\u001B[0m         \u001B[1;31m# remove once script supports set_grad_enabled\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2182\u001B[0m         \u001B[0m_no_grad_embedding_renorm_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2183\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscale_grad_by_freq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msparse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2184\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2185\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "train(network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years\n"
     ]
    }
   ],
   "source": [
    "print(max(dsm.vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yermoliev\n"
     ]
    }
   ],
   "source": [
    "v = list(dsm.vocab.keys())\n",
    "print(v[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171678\n"
     ]
    }
   ],
   "source": [
    "print(dsm.vocab['yermoliev'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}